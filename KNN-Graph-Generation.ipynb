{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c80fda9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch_geometric as tg\n",
    "import networkx as nx\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "from src.dataset_utils import theta_ds_create\n",
    "from src.dataset_utils import S_ds_compute\n",
    "\n",
    "from src.phi import JTFS_forward\n",
    "from src.jacobian import M_factory\n",
    "from src.distances import distance_factory\n",
    "from src.ftm import rectangular_drum\n",
    "from src.ftm import constants as FTM_constants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-G Parameters\n",
    "\n",
    "n_hubs = 2000\n",
    "k = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d67ec",
   "metadata": {},
   "source": [
    "## Creating KNN-G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629679c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd78993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to read or create the parameters graphset and set the path according to it\n",
    "read_dataset = True\n",
    "\n",
    "if read_dataset:\n",
    "    DatasetPath = \"data/precompute_S/param_dataset.csv\"\n",
    "    S_DatasetPath = \"data/precompute_S/S_dataset_full.parquet\"\n",
    "else:\n",
    "    DatasetPath = \"data/default_parameters.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da973d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/Creating the dataset\n",
    "logscale = True\n",
    "if read_dataset:\n",
    "    DF = torch.from_numpy(pd.read_csv(DatasetPath).to_numpy()).to(torch.float)\n",
    "else:\n",
    "    bounds = [['omega', 'tau', 'p', 'd', 'alpha'],[(2.4, 3.8),(0.4, 3),(-5, -0.7),(-5, -0.5),(10e-05, 1)]]\n",
    "    DF = torch.from_numpy(theta_ds_create(bounds=bounds, subdiv=5, path='data/default_parameters.csv').to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f40889",
   "metadata": {},
   "source": [
    "### Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c40cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,    50,   100,  ..., 99898, 99948, 99999])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing the initial hubs\n",
    "\n",
    "n_dataset = DF.size(dim=0)\n",
    "Id_hub = torch.linspace(0, n_dataset-1, steps=n_hubs).long()\n",
    "\n",
    "Id_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec3dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading S: 100%|██████████| 20/20 [01:37<00:00,  4.89s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.1219, 5.9250, 5.3349,  ..., 3.5671, 2.7955, 2.1095],\n",
       "        [6.2008, 6.0038, 5.4136,  ..., 3.6870, 2.9022, 2.2149],\n",
       "        [6.2217, 6.0247, 5.4344,  ..., 3.6131, 2.8381, 2.1647],\n",
       "        ...,\n",
       "        [2.6765, 2.4917, 1.9642,  ..., 2.2821, 2.3521, 2.5454],\n",
       "        [2.2671, 2.0901, 1.5930,  ..., 1.9963, 1.7524, 1.7293],\n",
       "        [2.9475, 2.7602, 2.2185,  ..., 2.2782, 2.1937, 2.2938]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read/Compute the S(hubs)  \n",
    "\n",
    "def S_hub_from_dataset(ds_path, Id_hub):\n",
    "        id_hub_list = Id_hub.tolist()\n",
    "        parquet_file = pq.ParquetFile(ds_path)\n",
    "        S_hub = []\n",
    "        for i in tqdm.tqdm(range(parquet_file.num_row_groups), desc=\"Reading S\"):\n",
    "            table = parquet_file.read_row_group(i)\n",
    "            mask = pc.is_in(table[\"row_id\"], pyarrow.array(id_hub_list))\n",
    "            filtered_table = table.filter(mask)\n",
    "            S_batch_cpu = torch.from_numpy(np.array(filtered_table.drop([\"row_id\"])))\n",
    "            S_hub.append(S_batch_cpu)\n",
    "\n",
    "        return torch.cat(S_hub)\n",
    "\n",
    "\n",
    "if read_dataset :\n",
    "    S_hub = S_hub_from_dataset(S_DatasetPath, Id_hub)\n",
    "else:\n",
    "    phi = JTFS_forward\n",
    "    def S(theta):\n",
    "        return phi(rectangular_drum(theta, logscale, **FTM_constants))\n",
    "    S_hub = S_ds_compute(DF,Id_hub,S)\n",
    "\n",
    "S_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing M: 100%|██████████| 2000/2000 [37:09<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2407e+07, -2.7094e+05, -3.3470e+04,  8.8866e+05, -3.7140e+09],\n",
       "         [-2.7094e+05,  1.3639e+05, -1.2047e+04, -3.9639e+03,  6.9533e+07],\n",
       "         [-3.3470e+04, -1.2047e+04,  9.8887e+03, -7.0240e+03, -1.2441e+07],\n",
       "         [ 8.8866e+05, -3.9639e+03, -7.0240e+03,  1.8342e+05, -7.6607e+08],\n",
       "         [-3.7140e+09,  6.9533e+07, -1.2441e+07, -7.6607e+08,  3.3810e+12]],\n",
       "\n",
       "        [[ 4.1696e+07, -4.7373e+05,  2.0811e+03,  3.5975e+05, -1.4963e+09],\n",
       "         [-4.7373e+05,  1.5188e+05, -6.6852e+02, -1.5087e+04,  6.6798e+07],\n",
       "         [ 2.0811e+03, -6.6852e+02,  1.4835e+02,  1.0990e+03, -5.4160e+06],\n",
       "         [ 3.5975e+05, -1.5087e+04,  1.0990e+03,  3.1595e+05, -1.3768e+09],\n",
       "         [-1.4963e+09,  6.6798e+07, -5.4160e+06, -1.3768e+09,  6.0025e+12]],\n",
       "\n",
       "        [[ 3.3852e+07, -2.8389e+05, -4.7504e+04,  5.2237e+05, -2.0623e+09],\n",
       "         [-2.8389e+05,  1.3604e+05, -1.2689e+04, -8.4213e+03,  9.1682e+07],\n",
       "         [-4.7504e+04, -1.2689e+04,  1.3967e+04, -1.0140e+04, -1.6619e+07],\n",
       "         [ 5.2237e+05, -8.4213e+03, -1.0140e+04,  1.3533e+05, -5.4370e+08],\n",
       "         [-2.0623e+09,  9.1682e+07, -1.6619e+07, -5.4370e+08,  2.4334e+12]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.3803e+12, -1.4460e+07,  2.0300e+07,  5.9633e+11, -1.2103e+11],\n",
       "         [-1.4460e+07,  2.4957e+03, -7.1949e+03,  7.5136e+05,  6.0026e+05],\n",
       "         [ 2.0300e+07, -7.1949e+03,  3.1041e+04,  3.1302e+06, -3.8883e+06],\n",
       "         [ 5.9633e+11,  7.5136e+05,  3.1302e+06,  4.3008e+11, -7.5640e+10],\n",
       "         [-1.2103e+11,  6.0026e+05, -3.8883e+06, -7.5640e+10,  8.6706e+10]],\n",
       "\n",
       "        [[ 8.3395e+11, -8.5804e+06,  2.2983e+07, -3.0254e+05, -1.5940e+09],\n",
       "         [-8.5804e+06,  2.7076e+03, -1.2170e+04, -2.1283e+00,  3.5020e+04],\n",
       "         [ 2.2983e+07, -1.2170e+04,  6.5154e+04,  2.9523e+01, -1.2276e+05],\n",
       "         [-3.0254e+05, -2.1283e+00,  2.9523e+01,  2.8225e+00,  2.8011e+04],\n",
       "         [-1.5940e+09,  3.5020e+04, -1.2276e+05,  2.8011e+04,  2.7423e+09]],\n",
       "\n",
       "        [[ 2.5895e+12, -1.0349e+07, -2.0115e+06,  2.8941e+11, -4.4857e+04],\n",
       "         [-1.0349e+07,  1.9073e+03, -7.5236e+03,  1.5809e+06,  1.1835e-01],\n",
       "         [-2.0115e+06, -7.5236e+03,  4.2865e+04, -6.8434e+06,  1.8213e-01],\n",
       "         [ 2.8941e+11,  1.5809e+06, -6.8434e+06,  3.1294e+11, -1.1257e+04],\n",
       "         [-4.4857e+04,  1.1835e-01,  1.8213e-01, -1.1257e+04,  9.1599e-04]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the M(hub) with multiprocessing\n",
    "\n",
    "from src.M_multiprocessing import init_worker_M, compute_task_M\n",
    "\n",
    "phi = JTFS_forward\n",
    "\n",
    "def run_parallel():\n",
    "    num_tasks = Id_hub.size(0)\n",
    "    num_processes = 2  \n",
    "    \n",
    "    # Prepare task arguments\n",
    "    tasks = [(i, DF[Id_hub[i], :], device) for i in range(num_tasks)]\n",
    "\n",
    "    M_hub = torch.zeros(num_tasks, DF.size(1), DF.size(1))\n",
    "\n",
    "    ctx = torch.multiprocessing.get_context('spawn')\n",
    "    \n",
    "    with ctx.Pool(\n",
    "        processes=num_processes,\n",
    "        initializer=init_worker_M,\n",
    "        initargs=(M_factory, logscale, phi, device)\n",
    "    ) as pool:\n",
    "        \n",
    "        for idx, result in tqdm.tqdm(pool.imap_unordered(compute_task_M, tasks), total=num_tasks, desc=\"Computing M\"):\n",
    "            M_hub[idx] = result\n",
    "            \n",
    "    return M_hub\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    M_hub = run_parallel()\n",
    "\n",
    "M_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c817b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(M_hub,'data/Knn-G/M_hub.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a31d66",
   "metadata": {},
   "source": [
    "### Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e812aa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,   46,   88,  ..., 1999, 1999, 1999])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hubs = DF[Id_hub] \n",
    "diff = hubs.unsqueeze(0) - DF.unsqueeze(1)\n",
    "\n",
    "distances = torch.einsum('nka,kab,nkb->nk', diff, M_hub, diff)\n",
    "\n",
    "Allocation = torch.argmin(distances, dim=1)\n",
    "\n",
    "Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052ff502",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Allocation,'data/Knn-G/Allocation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2da8b",
   "metadata": {},
   "source": [
    "### Graph from KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67c7a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If reloading stuff\n",
    "\n",
    "M_hub = torch.load('data/Knn-G/M_hub_2000h.pt').cpu()\n",
    "Allocation = torch.load('data/Knn-G/Allocation_full.pt').cpu()\n",
    "#print(M_hub.size())\n",
    "#print(Allocation.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0122a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "DF = DF.to(device)\n",
    "M_all = M_hub[Allocation].to(device)  \n",
    "\n",
    "def D_vmap(theta_c, M_c, theta_r, M_r):\n",
    "    d1 = distance_PNP(theta_c, theta_r, M_r)\n",
    "    d2 = distance_PNP(theta_r, theta_c, M_c)\n",
    "    return (d1 + d2) / 2\n",
    "\n",
    "compute_row = torch.vmap(\n",
    "    lambda tc, mc, tr, mr: D_vmap(tc, mc, tr, mr),\n",
    "    in_dims=(0, 0, None, None) \n",
    ")\n",
    "\n",
    "def Knn_edge(k, batch_size=128):\n",
    "    \"\"\"\n",
    "    k-NN graph construction.\n",
    "    \"\"\"\n",
    "    num_nodes = DF.size(0)\n",
    "    sources_list = []\n",
    "    targets_list = []\n",
    "    weights_list = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, num_nodes, batch_size), desc='Computing Edges'):\n",
    "        start = i\n",
    "        end = min(i + batch_size, num_nodes)\n",
    "        \n",
    "        batch_theta = DF[start:end]   \n",
    "        batch_M = M_all[start:end]     \n",
    "        \n",
    "        dists_batch = []\n",
    "        for b in range(end - start):\n",
    "\n",
    "            d_row = compute_row(DF, M_all, batch_theta[b], batch_M[b]).cpu()\n",
    "            dists_batch.append(d_row)\n",
    "        \n",
    "        dists_batch = torch.stack(dists_batch)\n",
    "\n",
    "        vals, cols = torch.topk(dists_batch, k=k+1, dim=1, largest=False)\n",
    "\n",
    "        rows = torch.arange(start, end, device=device).unsqueeze(1).repeat(1, k+1).cpu()\n",
    "        \n",
    "        mask = rows != cols\n",
    "        \n",
    "        valid_rows = rows[mask]\n",
    "        valid_cols = cols[mask]\n",
    "        valid_vals = vals[mask]\n",
    "\n",
    "        # Both ways to get a symmetric graph\n",
    "        sources_list.append(valid_rows)\n",
    "        targets_list.append(valid_cols)\n",
    "        weights_list.append(valid_vals) \n",
    "        \n",
    "        sources_list.append(valid_cols)\n",
    "        targets_list.append(valid_rows)\n",
    "        weights_list.append(valid_vals)\n",
    "\n",
    "    all_sources = torch.cat(sources_list)\n",
    "    all_targets = torch.cat(targets_list)\n",
    "    all_weights = torch.cat(weights_list)\n",
    "    \n",
    "    edge_index = torch.stack([all_sources, all_targets], dim=0)\n",
    "    \n",
    "    return edge_index, all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cded5eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Edges: 100%|██████████| 782/782 [02:10<00:00,  6.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[100000, 5], edge_index=[2, 1200000], edge_attr=[1200000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Graph Data object\n",
    "\n",
    "edge_index,edge_attr = Knn_edge(k)\n",
    "\n",
    "graph = tg.data.Data(x=DF, edge_index=edge_index, edge_attr=edge_attr)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "870c6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(graph, 'data/Knn-G/tgGraph.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50e8b7",
   "metadata": {},
   "source": [
    "## Writing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2bfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[100000, 5], edge_index=[2, 10000000], edge_attr=[10000000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If reloading stuff\n",
    "\n",
    "#graph = torch.load('data/Knn-G/tgGraph_full.pt',weights_only=False)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 100000\n",
      "Number of edges: 10000000\n",
      "Average node degree: 100.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DataEdgeAttr(edge_type=None, layout=<EdgeLayout.COO: 'coo'>, is_sorted=False, size=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "#print(f'Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "#print(f'Has self-loops: {graph.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for small graph, else OOM very fast\n",
    "\n",
    "#G = tg.utils.to_networkx(graph, to_undirected=True, edge_attrs=[\"edge_attr\"], node_attrs=[\"x\"])\n",
    "#G\n",
    "#PathGraph = 'data/Knn-G/knnG.gml'\n",
    "#nx.write_gml(G, PathGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_graphml(data, filename):\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # Prepare attributes\n",
    "    edge_weights = data.edge_attr.cpu().numpy() if hasattr(data, 'edge_attr') else None\n",
    "    node_features = data.x.cpu().numpy() if hasattr(data, 'x') else None\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        # 1. Header and Schema Definitions\n",
    "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        f.write('<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\" \\n')\n",
    "        f.write('         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \\n')\n",
    "        f.write('         xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">\\n')\n",
    "        \n",
    "        # Define Attributes (Crucial for Gephi)\n",
    "        f.write('  <key id=\"v_feat\" for=\"node\" attr.name=\"features\" attr.type=\"string\"/>\\n')\n",
    "        f.write('  <key id=\"e_weight\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\"/>\\n')\n",
    "        \n",
    "        f.write('  <graph id=\"G\" edgedefault=\"directed\">\\n')\n",
    "\n",
    "        # 2. Write Nodes\n",
    "        for i in tqdm.tqdm(range(num_nodes),desc='Nodes'):\n",
    "            f.write(f'    <node id=\"n{i}\">\\n')\n",
    "            if node_features is not None:\n",
    "                feat_str = \",\".join(map(str, node_features[i]))\n",
    "                f.write(f'      <data key=\"v_feat\">{feat_str}</data>\\n')\n",
    "            f.write('    </node>\\n')\n",
    "\n",
    "        # 3. Write Edges\n",
    "        sources = edge_index[0]\n",
    "        targets = edge_index[1]\n",
    "        \n",
    "        for idx in tqdm.tqdm(range(len(sources)),desc='Edges'):\n",
    "            # Write edge with optional weight\n",
    "            if edge_weights is not None:\n",
    "                w = edge_weights[idx].item() if hasattr(edge_weights[idx], \"item\") else edge_weights[idx]\n",
    "                f.write(f'    <edge source=\"n{sources[idx]}\" target=\"n{targets[idx]}\">\\n')\n",
    "                f.write(f'      <data key=\"e_weight\">{w}</data>\\n')\n",
    "                f.write('    </edge>\\n')\n",
    "            else:\n",
    "                f.write(f'    <edge source=\"n{sources[idx]}\" target=\"n{targets[idx]}\"/>\\n')\n",
    "\n",
    "        f.write('  </graph>\\n')\n",
    "        f.write('</graphml>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed82b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 100000/100000 [00:00<00:00, 248690.32it/s]\n",
      "Edges: 100%|██████████| 10000000/10000000 [00:36<00:00, 270904.38it/s]\n"
     ]
    }
   ],
   "source": [
    "save_to_graphml(graph,'data/Knn-G/KnnG_full.graphml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
