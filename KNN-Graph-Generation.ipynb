{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c80fda9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch_geometric as tg\n",
    "import networkx as nx\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "from src.dataset_utils import theta_ds_create\n",
    "from src.dataset_utils import S_ds_compute\n",
    "\n",
    "from src.phi import JTFS_forward\n",
    "from src.jacobian import M_factory\n",
    "from src.distances import distance_factory\n",
    "from src.ftm import rectangular_drum\n",
    "from src.ftm import constants as FTM_constants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e8a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-G Parameters\n",
    "\n",
    "n_hubs = 2000\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d67ec",
   "metadata": {},
   "source": [
    "## Creating KNN-G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629679c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd78993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to read or create the parameters graphset and set the path according to it\n",
    "read_dataset = True\n",
    "\n",
    "if read_dataset:\n",
    "    DatasetPath = \"data/precompute_S/param_dataset.csv\"\n",
    "    S_DatasetPath = \"data/precompute_S/S_dataset_full.parquet\"\n",
    "else:\n",
    "    DatasetPath = \"data/default_parameters.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da973d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/Creating the dataset\n",
    "logscale = True\n",
    "if read_dataset:\n",
    "    DF = torch.from_numpy(pd.read_csv(DatasetPath).to_numpy()).to(torch.float)\n",
    "else:\n",
    "    bounds = [['omega', 'tau', 'p', 'd', 'alpha'],[(2.4, 3.8),(0.4, 3),(-5, -0.7),(-5, -0.5),(10e-05, 1)]]\n",
    "    DF = torch.from_numpy(theta_ds_create(bounds=bounds, subdiv=5, path='data/default_parameters.csv').to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f40889",
   "metadata": {},
   "source": [
    "### Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c40cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the initial hubs\n",
    "\n",
    "n_dataset = DF.size(dim=0)\n",
    "Id_hub = torch.linspace(0, n_dataset-1, steps=n_hubs).long()\n",
    "\n",
    "Id_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/Compute the S(hubs)  \n",
    "\n",
    "def S_hub_from_dataset(ds_path, Id_hub):\n",
    "        id_hub_list = Id_hub.tolist()\n",
    "        parquet_file = pq.ParquetFile(ds_path)\n",
    "        S_hub = []\n",
    "        for i in tqdm.tqdm(range(parquet_file.num_row_groups), desc=\"Reading S\"):\n",
    "            table = parquet_file.read_row_group(i)\n",
    "            mask = pc.is_in(table[\"row_id\"], pyarrow.array(id_hub_list))\n",
    "            filtered_table = table.filter(mask)\n",
    "            S_batch_cpu = torch.from_numpy(np.array(filtered_table.drop([\"row_id\"])))\n",
    "            S_hub.append(S_batch_cpu)\n",
    "\n",
    "        return torch.cat(S_hub)\n",
    "\n",
    "\n",
    "if read_dataset :\n",
    "    S_hub = S_hub_from_dataset(S_DatasetPath, Id_hub)\n",
    "else:\n",
    "    phi = JTFS_forward\n",
    "    def S(theta):\n",
    "        return phi(rectangular_drum(theta, logscale, **FTM_constants))\n",
    "    S_hub = S_ds_compute(DF,Id_hub,S)\n",
    "\n",
    "S_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the M(hub) with multiprocessing\n",
    "\n",
    "from src.M_multiprocessing import init_worker_M, compute_task_M\n",
    "\n",
    "phi = JTFS_forward\n",
    "\n",
    "def run_parallel():\n",
    "    num_tasks = Id_hub.size(0)\n",
    "    num_processes = 2  \n",
    "    \n",
    "    # Prepare task arguments\n",
    "    tasks = [(i, DF[Id_hub[i], :], device) for i in range(num_tasks)]\n",
    "\n",
    "    M_hub = torch.zeros(num_tasks, DF.size(1), DF.size(1))\n",
    "\n",
    "    ctx = torch.multiprocessing.get_context('spawn')\n",
    "    \n",
    "    with ctx.Pool(\n",
    "        processes=num_processes,\n",
    "        initializer=init_worker_M,\n",
    "        initargs=(M_factory, logscale, phi, device)\n",
    "    ) as pool:\n",
    "        \n",
    "        for idx, result in tqdm.tqdm(pool.imap_unordered(compute_task_M, tasks), total=num_tasks, desc=\"Computing M\"):\n",
    "            M_hub[idx] = result\n",
    "            \n",
    "    return M_hub\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    M_hub = run_parallel()\n",
    "\n",
    "M_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c817b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(M_hub,'data/Knn-G/M_hub.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a31d66",
   "metadata": {},
   "source": [
    "### Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "def F(i,j,h):\n",
    "    \"\"\"\n",
    "    i dans [0,DF.size(dim=0)-1]\n",
    "    j dans [0,DF.size(dim=0)-1]\n",
    "    h dans [0,Id_hub.size(dim=0)-1]\n",
    "    \"\"\"\n",
    "    return distance_PNP(DF[i,:],DF[j,:],M_hub[h,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation of each point\n",
    "\n",
    "Allocation = torch.zeros(DF.size(dim=0)).to(int).to(device)\n",
    "\n",
    "for i in tqdm.tqdm(range(DF.size(dim=0)),desc='Allocating',leave=True):\n",
    "\n",
    "    dmin = torch.inf\n",
    "    argmin = None\n",
    "\n",
    "    for k in range(Id_hub.size(dim=0)):\n",
    "        d = F(i,Id_hub[k],k)\n",
    "        if d<dmin:\n",
    "            dmin = d\n",
    "            argmin = k\n",
    "        \n",
    "    Allocation[i] = argmin\n",
    "\n",
    "Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ff502",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Allocation,'data/Knn-G/Allocation.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2da8b",
   "metadata": {},
   "source": [
    "### Graph from KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c7a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 5, 5])\n",
      "torch.Size([100000])\n"
     ]
    }
   ],
   "source": [
    "#If reloading stuff\n",
    "\n",
    "M_hub = torch.load('data/Knn-G/M_hub_full.pt')\n",
    "Allocation = torch.load('data/Knn-G/Allocation_full.pt')\n",
    "print(M_hub.size())\n",
    "print(Allocation.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0122a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "DF = DF.to(device)\n",
    "M_hub = M_hub.to(device)\n",
    "Allocation = Allocation.to(device)\n",
    "\n",
    "M_all = M_hub[Allocation]  \n",
    "\n",
    "def D_vmap(theta_c, M_c, theta_r, M_r):\n",
    "    d1 = distance_PNP(theta_c, theta_r, M_r)\n",
    "    d2 = distance_PNP(theta_r, theta_c, M_c)\n",
    "    return (d1 + d2) / 2\n",
    "\n",
    "compute_row = torch.vmap(\n",
    "    lambda tc, mc, tr, mr: D_vmap(tc, mc, tr, mr),\n",
    "    in_dims=(0, 0, None, None) \n",
    ")\n",
    "\n",
    "def Knn_edge(k, batch_size=128):\n",
    "    \"\"\"\n",
    "    k-NN graph construction.\n",
    "    \"\"\"\n",
    "    num_nodes = DF.size(0)\n",
    "    sources_list = []\n",
    "    targets_list = []\n",
    "    weights_list = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, num_nodes, batch_size), desc='Computing Edges'):\n",
    "        start = i\n",
    "        end = min(i + batch_size, num_nodes)\n",
    "        \n",
    "        batch_theta = DF[start:end]   \n",
    "        batch_M = M_all[start:end]     \n",
    "        \n",
    "        dists_batch = []\n",
    "        for b in range(end - start):\n",
    "\n",
    "            d_row = compute_row(DF, M_all, batch_theta[b], batch_M[b])\n",
    "            dists_batch.append(d_row)\n",
    "        \n",
    "        dists_batch = torch.stack(dists_batch)\n",
    "\n",
    "        vals, cols = torch.topk(dists_batch, k=k+1, dim=1, largest=False)\n",
    "\n",
    "        rows = torch.arange(start, end, device=device).unsqueeze(1).repeat(1, k+1)\n",
    "        \n",
    "        mask = rows != cols\n",
    "        \n",
    "        valid_rows = rows[mask]\n",
    "        valid_cols = cols[mask]\n",
    "        valid_vals = vals[mask]\n",
    "\n",
    "        # Both ways to get a symmetric graph\n",
    "        sources_list.append(valid_rows)\n",
    "        targets_list.append(valid_cols)\n",
    "        weights_list.append(valid_vals) \n",
    "        \n",
    "        sources_list.append(valid_cols)\n",
    "        targets_list.append(valid_rows)\n",
    "        weights_list.append(valid_vals)\n",
    "\n",
    "    all_sources = torch.cat(sources_list)\n",
    "    all_targets = torch.cat(targets_list)\n",
    "    all_weights = torch.cat(weights_list)\n",
    "    \n",
    "    edge_index = torch.stack([all_sources, all_targets], dim=0)\n",
    "    \n",
    "    return edge_index, all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cded5eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Edges: 100%|██████████| 782/782 [01:24<00:00,  9.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[100000, 5], edge_index=[2, 10000000], edge_attr=[10000000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Graph Data object\n",
    "\n",
    "edge_index,edge_attr = Knn_edge(k)\n",
    "\n",
    "graph = tg.data.Data(x=DF, edge_index=edge_index, edge_attr=edge_attr)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(graph, 'data/Knn-G/tgGraph.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50e8b7",
   "metadata": {},
   "source": [
    "## Writing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2bfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[100000, 5], edge_index=[2, 10000000], edge_attr=[10000000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If reloading stuff\n",
    "\n",
    "#graph = torch.load('data/Knn-G/tgGraph_full.pt',weights_only=False)\n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 100000\n",
      "Number of edges: 10000000\n",
      "Average node degree: 100.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DataEdgeAttr(edge_type=None, layout=<EdgeLayout.COO: 'coo'>, is_sorted=False, size=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "#print(f'Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "#print(f'Has self-loops: {graph.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only for small graph, else OOM very fast\n",
    "\n",
    "#G = tg.utils.to_networkx(graph, to_undirected=True, edge_attrs=[\"edge_attr\"], node_attrs=[\"x\"])\n",
    "#G\n",
    "#PathGraph = 'data/Knn-G/knnG.gml'\n",
    "#nx.write_gml(G, PathGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_graphml_gephi(data, filename):\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # Prepare attributes\n",
    "    edge_weights = data.edge_attr.cpu().numpy() if hasattr(data, 'edge_attr') else None\n",
    "    node_features = data.x.cpu().numpy() if hasattr(data, 'x') else None\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        # 1. Header and Schema Definitions\n",
    "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        f.write('<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\" \\n')\n",
    "        f.write('         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \\n')\n",
    "        f.write('         xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">\\n')\n",
    "        \n",
    "        # Define Attributes (Crucial for Gephi)\n",
    "        f.write('  <key id=\"v_feat\" for=\"node\" attr.name=\"features\" attr.type=\"string\"/>\\n')\n",
    "        f.write('  <key id=\"e_weight\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\"/>\\n')\n",
    "        \n",
    "        f.write('  <graph id=\"G\" edgedefault=\"directed\">\\n')\n",
    "\n",
    "        # 2. Write Nodes\n",
    "        for i in tqdm.tqdm(range(num_nodes),desc='Nodes'):\n",
    "            f.write(f'    <node id=\"n{i}\">\\n')\n",
    "            if node_features is not None:\n",
    "                feat_str = \",\".join(map(str, node_features[i]))\n",
    "                f.write(f'      <data key=\"v_feat\">{feat_str}</data>\\n')\n",
    "            f.write('    </node>\\n')\n",
    "\n",
    "        # 3. Write Edges\n",
    "        sources = edge_index[0]\n",
    "        targets = edge_index[1]\n",
    "        \n",
    "        for idx in tqdm.tqdm(range(len(sources)),desc='Edges'):\n",
    "            # Write edge with optional weight\n",
    "            if edge_weights is not None:\n",
    "                w = edge_weights[idx].item() if hasattr(edge_weights[idx], \"item\") else edge_weights[idx]\n",
    "                f.write(f'    <edge source=\"n{sources[idx]}\" target=\"n{targets[idx]}\">\\n')\n",
    "                f.write(f'      <data key=\"e_weight\">{w}</data>\\n')\n",
    "                f.write('    </edge>\\n')\n",
    "            else:\n",
    "                f.write(f'    <edge source=\"n{sources[idx]}\" target=\"n{targets[idx]}\"/>\\n')\n",
    "\n",
    "        f.write('  </graph>\\n')\n",
    "        f.write('</graphml>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ed82b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 100000/100000 [00:00<00:00, 248690.32it/s]\n",
      "Edges: 100%|██████████| 10000000/10000000 [00:36<00:00, 270904.38it/s]\n"
     ]
    }
   ],
   "source": [
    "save_to_graphml_gephi(graph,'data/Knn-G/KnnG_full.graphml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
