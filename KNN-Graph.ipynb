{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c80fda9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch_geometric as tg\n",
    "import networkx as nx\n",
    "\n",
    "from src.dataset_utils import theta_ds_create\n",
    "from src.dataset_utils import S_ds_read_given_rows_batch, S_ds_compute\n",
    "\n",
    "from src.phi import JTFS_forward\n",
    "from src.jacobian import M_factory\n",
    "from src.distances import distance_factory\n",
    "from src.ftm import rectangular_drum\n",
    "from src.ftm import constants as FTM_constants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-G Parameters\n",
    "\n",
    "n_hubs = 100\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d67ec",
   "metadata": {},
   "source": [
    "## Creating KNN-G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629679c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd78993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to read or create the parameters graphset and set the path according to it\n",
    "\n",
    "read_dataset = False\n",
    "\n",
    "if read_dataset:\n",
    "    DatasetPath = \"data/precompute_S/param_dataset.csv\"\n",
    "    S_DatasetPath = \"data/precompute_S/S_dataset_full.parquet\"\n",
    "else:\n",
    "    DatasetPath = \"data/default_parameters.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da973d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/Creating the dataset\n",
    "\n",
    "if read_dataset:\n",
    "    DF = torch.from_numpy(pd.read_csv(DatasetPath).to_numpy()).to(device).to(torch.float)\n",
    "else:\n",
    "    bounds = [['omega', 'tau', 'p', 'd', 'alpha'],[(2.4, 3.8),(0.4, 3),(-5, -0.7),(-5, -0.5),(10e-05, 1)]]\n",
    "    logscale = True\n",
    "    DF = torch.from_numpy(theta_ds_create(bounds=bounds, subdiv=5, path='data/default_parameters.csv').to_numpy()).to(device).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f40889",
   "metadata": {},
   "source": [
    "### Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c40cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the initial hubs\n",
    "\n",
    "n_dataset = DF.size(dim=0)\n",
    "Id_hub = torch.linspace(0, n_dataset-1, steps=n_hubs, device=device).long()\n",
    "\n",
    "Id_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/Compute the S(hubs)  \n",
    "\n",
    "#Can't read too many indices at once or else the RAM will be filled very fast, so we do it in batch (1 batch = 35s so less than 70 per batch = slower than computing)\n",
    "enough_ram = False \n",
    "\n",
    "if read_dataset and enough_ram:\n",
    "    batch_size = 70\n",
    "    S_hub = S_ds_read_given_rows_batch(S_DatasetPath, Id_hub, batch_size)\n",
    "else:\n",
    "    phi = JTFS_forward\n",
    "    def S(theta):\n",
    "        return phi(rectangular_drum(theta, logscale, **FTM_constants))\n",
    "    S_hub = S_ds_compute(DF,Id_hub,S)\n",
    "\n",
    "S_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the M(hubs)\n",
    "\n",
    "phi = JTFS_forward\n",
    "M = M_factory(logscale,phi)\n",
    "\n",
    "M_hub = torch.zeros(Id_hub.size(dim=0),DF.size(dim=1),DF.size(dim=1)).to(device)\n",
    "\n",
    "for i in tqdm.tqdm(range(Id_hub.size(dim=0)), desc=\"Computing M\", leave=True):\n",
    "    M_hub[i,:,:] = M(DF[Id_hub[i],:])\n",
    "\n",
    "M_hub[0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a31d66",
   "metadata": {},
   "source": [
    "### Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "def F(i,j,h):\n",
    "    \"\"\"\n",
    "    i dans [0,DF.size(dim=0)-1]\n",
    "    j dans [0,DF.size(dim=0)-1]\n",
    "    h dans [0,Id_hub.size(dim=0)-1]\n",
    "    \"\"\"\n",
    "    return distance_PNP(DF[i,:],DF[j,:],M_hub[h,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation of each point\n",
    "\n",
    "Allocation = torch.zeros(DF.size(dim=0)).to(int).to(device)\n",
    "\n",
    "for i in tqdm.tqdm(range(DF.size(dim=0)),desc='Allocating',leave=True):\n",
    "\n",
    "    dmin = torch.inf\n",
    "    argmin = None\n",
    "\n",
    "    for k in range(Id_hub.size(dim=0)):\n",
    "        d = F(i,Id_hub[k],k)\n",
    "        if d<dmin:\n",
    "            dmin = d\n",
    "            argmin = k\n",
    "        \n",
    "    Allocation[i] = argmin\n",
    "\n",
    "Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2da8b",
   "metadata": {},
   "source": [
    "### Graph from KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance with hubs\n",
    "\n",
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "def D(theta_c,M_c,theta_r,M_r):\n",
    "    \"\"\"\n",
    "    Average of both ways to solve problem with distance across hubs\n",
    "    \"\"\"\n",
    "    return (distance_PNP(theta_c,theta_r,M_r)+distance_PNP(theta_r,theta_c,M_c))/2\n",
    "\n",
    "def all_D(i):\n",
    "    \"\"\"\n",
    "    i in [0,DF.size(dim=0)]\n",
    "    \"\"\"\n",
    "    M_i = M_hub[Allocation[i]]\n",
    "    T_M_j = torch.zeros(DF.size(dim=0),DF.size(dim=1),DF.size(dim=1)).to(device)\n",
    "    for j in range(DF.size(dim=0)):\n",
    "        T_M_j[j] = M_hub[Allocation[j]]\n",
    " \n",
    "    all_D_vmap = torch.func.vmap(functools.partial(D,theta_r=DF[i,:],M_r=M_i),in_dims=(0,0))\n",
    "\n",
    "    return all_D_vmap(DF, T_M_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge index \n",
    "\n",
    "def Knn_edge():\n",
    "    \"\"\"\n",
    "    edge_index : 1 if one point in neighbour of the other OR vice-versa\n",
    "    edge_attr : w(i,j) = 1/D(i,j)\n",
    "    \"\"\"\n",
    "    COO_edges = [[],[]]\n",
    "\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(DF.size(dim=0)),desc='Finding neighbours',leave=True):\n",
    "\n",
    "        T_dist = all_D(i)\n",
    "\n",
    "        T_dist_sorted,i_c_sorted = torch.sort(T_dist)\n",
    "\n",
    "        for j in i_c_sorted[0:k+1]:\n",
    "            if i!=j: #No self connections \n",
    "                COO_edges[0].append(i)\n",
    "                COO_edges[1].append(j)\n",
    "                COO_edges[1].append(i)\n",
    "                COO_edges[0].append(j)\n",
    "        \n",
    "                edge_attr.append(1/T_dist_sorted[j])\n",
    "                edge_attr.append(1/T_dist_sorted[j])\n",
    "\n",
    "    return torch.tensor(COO_edges, dtype=torch.long).to(device),edge_attr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph Data object\n",
    "\n",
    "edge_index,edge_attr = Knn_edge()\n",
    "\n",
    "graph = tg.data.Data(x=DF, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50e8b7",
   "metadata": {},
   "source": [
    "## Visualisation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(G,pos):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G,pos=pos,with_labels=False,node_size=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = tg.utils.to_networkx(graph, to_undirected=True)\n",
    "\n",
    "nx.write_graphml(G, 'data/Knn-G/knnG.graphml')\n",
    "\n",
    "pos = nx.forceatlas2_layout(G,gravity=0.1)\n",
    "#pos = nx.spring_layout(G)\n",
    "visualize_graph(G,pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
