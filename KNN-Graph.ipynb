{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c80fda9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import torch_geometric as tg\n",
    "import networkx as nx\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "from src.dataset_utils import theta_ds_create\n",
    "from src.dataset_utils import S_ds_compute\n",
    "\n",
    "from src.phi import JTFS_forward\n",
    "from src.jacobian import M_factory\n",
    "from src.distances import distance_factory\n",
    "from src.ftm import rectangular_drum\n",
    "from src.ftm import constants as FTM_constants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e8a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN-G Parameters\n",
    "\n",
    "n_hubs = 2000\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d67ec",
   "metadata": {},
   "source": [
    "## Creating KNN-G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629679c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd78993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose to read or create the parameters graphset and set the path according to it\n",
    "read_dataset = True\n",
    "\n",
    "if read_dataset:\n",
    "    DatasetPath = \"data/precompute_S/param_dataset.csv\"\n",
    "    S_DatasetPath = \"data/precompute_S/S_dataset_full.parquet\"\n",
    "else:\n",
    "    DatasetPath = \"data/default_parameters.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da973d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/Creating the dataset\n",
    "logscale = True\n",
    "if read_dataset:\n",
    "    DF = torch.from_numpy(pd.read_csv(DatasetPath).to_numpy()).to(torch.float)\n",
    "else:\n",
    "    bounds = [['omega', 'tau', 'p', 'd', 'alpha'],[(2.4, 3.8),(0.4, 3),(-5, -0.7),(-5, -0.5),(10e-05, 1)]]\n",
    "    DF = torch.from_numpy(theta_ds_create(bounds=bounds, subdiv=5, path='data/default_parameters.csv').to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f40889",
   "metadata": {},
   "source": [
    "### Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c40cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,    50,   100,  ..., 99898, 99948, 99999], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing the initial hubs\n",
    "\n",
    "n_dataset = DF.size(dim=0)\n",
    "Id_hub = torch.linspace(0, n_dataset-1, steps=n_hubs).long()\n",
    "\n",
    "Id_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading in batch: 100%|██████████| 20/20 [01:48<00:00,  5.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6.1219, 5.9250, 5.3349,  ..., 3.5671, 2.7955, 2.1095],\n",
       "        [6.2008, 6.0038, 5.4136,  ..., 3.6870, 2.9022, 2.2149],\n",
       "        [6.2217, 6.0247, 5.4344,  ..., 3.6131, 2.8381, 2.1647],\n",
       "        ...,\n",
       "        [2.6765, 2.4917, 1.9642,  ..., 2.2821, 2.3521, 2.5454],\n",
       "        [2.2671, 2.0901, 1.5930,  ..., 1.9963, 1.7524, 1.7293],\n",
       "        [2.9475, 2.7602, 2.2185,  ..., 2.2782, 2.1937, 2.2938]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read/Compute the S(hubs)  \n",
    "\n",
    "def S_hub_from_dataset(ds_path, Id_hub):\n",
    "        id_hub_list = Id_hub.tolist()\n",
    "        parquet_file = pq.ParquetFile(ds_path)\n",
    "        S_hub = []\n",
    "        for i in tqdm.tqdm(range(parquet_file.num_row_groups), desc=\"Reading in batch\"):\n",
    "            table = parquet_file.read_row_group(i)\n",
    "            mask = pc.is_in(table[\"row_id\"], pyarrow.array(id_hub_list))\n",
    "            filtered_table = table.filter(mask)\n",
    "            S_batch_cpu = torch.from_numpy(np.array(filtered_table.drop([\"row_id\"])))\n",
    "            S_hub.append(S_batch_cpu)\n",
    "\n",
    "        return torch.cat(S_hub)\n",
    "\n",
    "\n",
    "if read_dataset :\n",
    "    S_hub = S_hub_from_dataset(S_DatasetPath, Id_hub)\n",
    "else:\n",
    "    phi = JTFS_forward\n",
    "    def S(theta):\n",
    "        return phi(rectangular_drum(theta, logscale, **FTM_constants))\n",
    "    S_hub = S_ds_compute(DF,Id_hub,S)\n",
    "\n",
    "S_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the M(hub) with multiprocessing\n",
    "\n",
    "from src.M_multiprocessing import init_worker, compute_task\n",
    "\n",
    "phi = JTFS_forward\n",
    "\n",
    "def run_parallel():\n",
    "    num_tasks = Id_hub.size(0)\n",
    "    num_processes = 4  \n",
    "    \n",
    "    # Prepare task arguments\n",
    "    tasks = [(i, DF[Id_hub[i], :], device) for i in range(num_tasks)]\n",
    "\n",
    "    M_hub = torch.zeros(num_tasks, DF.size(1), DF.size(1))\n",
    "\n",
    "    ctx = torch.multiprocessing.get_context('spawn')\n",
    "    \n",
    "    with ctx.Pool(\n",
    "        processes=num_processes,\n",
    "        initializer=init_worker,\n",
    "        initargs=(M_factory, logscale, phi, device)\n",
    "    ) as pool:\n",
    "        \n",
    "        for idx, result in tqdm.tqdm(pool.imap_unordered(compute_task, tasks), total=num_tasks, desc=\"Computing M\"):\n",
    "            M_hub[idx] = result\n",
    "            \n",
    "    return M_hub\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    M_hub = run_parallel()\n",
    "\n",
    "M_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a31d66",
   "metadata": {},
   "source": [
    "### Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "def F(i,j,h):\n",
    "    \"\"\"\n",
    "    i dans [0,DF.size(dim=0)-1]\n",
    "    j dans [0,DF.size(dim=0)-1]\n",
    "    h dans [0,Id_hub.size(dim=0)-1]\n",
    "    \"\"\"\n",
    "    return distance_PNP(DF[i,:],DF[j,:],M_hub[h,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation of each point\n",
    "\n",
    "Allocation = torch.zeros(DF.size(dim=0)).to(int).to(device)\n",
    "\n",
    "for i in tqdm.tqdm(range(DF.size(dim=0)),desc='Allocating',leave=True):\n",
    "\n",
    "    dmin = torch.inf\n",
    "    argmin = None\n",
    "\n",
    "    for k in range(Id_hub.size(dim=0)):\n",
    "        d = F(i,Id_hub[k],k)\n",
    "        if d<dmin:\n",
    "            dmin = d\n",
    "            argmin = k\n",
    "        \n",
    "    Allocation[i] = argmin\n",
    "\n",
    "Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2da8b",
   "metadata": {},
   "source": [
    "### Graph from KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance with hubs\n",
    "\n",
    "distance_PNP = distance_factory('PNP')\n",
    "\n",
    "def D(theta_c,M_c,theta_r,M_r):\n",
    "    \"\"\"\n",
    "    Average of both ways to solve problem with distance across hubs\n",
    "    \"\"\"\n",
    "    return (distance_PNP(theta_c,theta_r,M_r)+distance_PNP(theta_r,theta_c,M_c))/2\n",
    "\n",
    "def all_D(i):\n",
    "    \"\"\"\n",
    "    i in [0,DF.size(dim=0)]\n",
    "    \"\"\"\n",
    "    M_i = M_hub[Allocation[i]]\n",
    "    T_M_j = torch.zeros(DF.size(dim=0),DF.size(dim=1),DF.size(dim=1)).to(device)\n",
    "    for j in range(DF.size(dim=0)):\n",
    "        T_M_j[j] = M_hub[Allocation[j]]\n",
    " \n",
    "    all_D_vmap = torch.func.vmap(functools.partial(D,theta_r=DF[i,:],M_r=M_i),in_dims=(0,0))\n",
    "\n",
    "    return all_D_vmap(DF, T_M_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge index \n",
    "\n",
    "def Knn_edge():\n",
    "    \"\"\"\n",
    "    edge_index : 1 if one point in neighbour of the other OR vice-versa\n",
    "    edge_attr : w(i,j) = 1/D(i,j)\n",
    "    \"\"\"\n",
    "    COO_edges = [[],[]]\n",
    "\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(DF.size(dim=0)),desc='Finding neighbours',leave=True):\n",
    "\n",
    "        T_dist = all_D(i)\n",
    "\n",
    "        T_dist_sorted,i_c_sorted = torch.sort(T_dist)\n",
    "\n",
    "        for j in i_c_sorted[0:k+1]:\n",
    "            if i!=j: #No self connections \n",
    "                COO_edges[0].append(i)\n",
    "                COO_edges[1].append(j)\n",
    "                COO_edges[1].append(i)\n",
    "                COO_edges[0].append(j)\n",
    "        \n",
    "                edge_attr.append(1/T_dist_sorted[j])\n",
    "                edge_attr.append(1/T_dist_sorted[j])\n",
    "\n",
    "    return torch.tensor(COO_edges, dtype=torch.long).to(device),edge_attr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph Data object\n",
    "\n",
    "edge_index,edge_attr = Knn_edge()\n",
    "\n",
    "graph = tg.data.Data(x=DF, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50e8b7",
   "metadata": {},
   "source": [
    "## Visualisation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {graph.num_nodes}')\n",
    "print(f'Number of edges: {graph.num_edges}')\n",
    "print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {graph.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(G,pos):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G,pos=pos,with_labels=False,node_size=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = tg.utils.to_networkx(graph, to_undirected=True)\n",
    "\n",
    "nx.write_graphml(G, 'data/Knn-G/knnG.graphml')\n",
    "\n",
    "pos = nx.forceatlas2_layout(G,gravity=0.1)\n",
    "#pos = nx.spring_layout(G)\n",
    "visualize_graph(G,pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
