{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c2eeb-840a-4946-9432-26cc1ca6a76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127a8c-52fc-456b-9503-eca3270ade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from src.forward import *\n",
    "from src.knn import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44998c3d-8efb-4f7d-aaff-f4004bcab699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Phi definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd00b1d3-0b58-4480-ad83-2ad9da31f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIRFilter(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_type=\"hp\", coef=0.85, fs=44100, ntaps=101, plot=False):\n",
    "\n",
    "        \"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\n",
    "        super(FIRFilter, self).__init__()\n",
    "        self.filter_type = filter_type\n",
    "        self.coef = coef\n",
    "        self.fs = fs\n",
    "        self.ntaps = ntaps\n",
    "        self.plot = plot\n",
    "\n",
    "        import scipy.signal\n",
    "\n",
    "        if ntaps % 2 == 0:\n",
    "            raise ValueError(f\"ntaps must be odd (ntaps={ntaps}).\")\n",
    "\n",
    "        if filter_type == \"hp\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, -coef, 0]).view(1, 1, -1)\n",
    "        elif filter_type == \"fd\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, 0, -coef]).view(1, 1, -1)\n",
    "        elif filter_type == \"aw\":\n",
    "            # Definition of analog A-weighting filter according to IEC/CD 1672.\n",
    "            f1 = 20.598997\n",
    "            f2 = 107.65265\n",
    "            f3 = 737.86223\n",
    "            f4 = 12194.217\n",
    "            A1000 = 1.9997\n",
    "\n",
    "            NUMs = [(2 * np.pi * f4) ** 2 * (10 ** (A1000 / 20)), 0, 0, 0, 0]\n",
    "            DENs = np.polymul(\n",
    "                [1, 4 * np.pi * f4, (2 * np.pi * f4) ** 2],\n",
    "                [1, 4 * np.pi * f1, (2 * np.pi * f1) ** 2],\n",
    "            )\n",
    "            DENs = np.polymul(\n",
    "                np.polymul(DENs, [1, 2 * np.pi * f3]), [1, 2 * np.pi * f2]\n",
    "            )\n",
    "\n",
    "            # convert analog filter to digital filter\n",
    "            b, a = scipy.signal.bilinear(NUMs, DENs, fs=fs)\n",
    "\n",
    "            # compute the digital filter frequency response\n",
    "            w_iir, h_iir = scipy.signal.freqz(b, a, worN=512, fs=fs)\n",
    "\n",
    "            # then we fit to 101 tap FIR filter with least squares\n",
    "            taps = scipy.signal.firls(ntaps, w_iir, abs(h_iir), fs=fs)\n",
    "\n",
    "            # now implement this digital FIR filter as a Conv1d layer\n",
    "            self.fir = torch.nn.Conv1d(\n",
    "                1, 1, kernel_size=ntaps, bias=False, padding=ntaps // 2\n",
    "            )\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor(taps.astype(\"float32\")).view(1, 1, -1)\n",
    "\n",
    "        self.fir.weight.data = self.fir.weight.data.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            input (Tensor): Predicted signal (B, #channels, #samples).\n",
    "            target (Tensor): Groundtruth signal (B, #channels, #samples).\n",
    "        Returns:\n",
    "            Tensor: Filtered signal.\n",
    "        \"\"\"\n",
    "        input = torch.nn.functional.conv1d(\n",
    "            input.unsqueeze(0).to(torch.float), self.fir.weight.data, padding=self.ntaps // 2\n",
    "        )\n",
    "        return input.squeeze(0).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1449854-d9e1-4f86-ba40-c69676fe25e5",
   "metadata": {},
   "source": [
    "### Create Parameters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67c2f51-28fe-4fad-a024-295d6041a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundaries\n",
    "\n",
    "bounds = [['omega', 'tau', 'p', 'd', 'alpha'],\n",
    " [(2.400247964468862, 3.798136579655672),\n",
    "  (0.0700188044714488, 0.7999966616122908),\n",
    "  (-4.999978530884291, -0.6989804486272966),\n",
    "  (-4.99983759075039, -0.5229983775344527),\n",
    "  (1.2362882382361523e-05, 0.9999649724709304)]]\n",
    "\n",
    "# Create DataFrame and write it to a CSV file for later use\n",
    "\n",
    "def create_DF(bounds=bounds, k=5, path='parameters.csv'):\n",
    "    \n",
    "    #Linspace of every parameters of size k\n",
    "    Dbase = np.zeros((k,5))\n",
    "    for i in range(5):\n",
    "        Dbase[:,i] = np.linspace(bounds[1][i][0],bounds[1][i][1],k)\n",
    "    baseDF = pd.DataFrame(data=Dbase,columns=bounds[0])\n",
    "\n",
    "    #Product of the linspaces to get all the possible combinations (size k**5, will take time)\n",
    "    D = list(product(baseDF['omega'],baseDF['tau'],baseDF['p'],baseDF['d'],baseDF['alpha']))\n",
    "    DF = pd.DataFrame(data=D,columns=bounds[0])\n",
    "\n",
    "    DF.to_csv(path)\n",
    "    \n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288970fa-6ec7-43d5-9ca5-de42be0ebd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this to recreate the parameters CSV, this can take a long time to finish depending on the subdivision k\n",
    "\n",
    "#create_DF(bounds=bounds, k=5, path='default_parameters.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ae66-407e-4d72-b5d3-ba10952adeef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Naive k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10daf5a-e2ef-423f-8bdc-2ab55e51920a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3515fc4-0364-40c1-93e6-e420c076dd9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Approximated k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33743ea-c02a-4190-b362-9029c32f327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the M matrix\n",
    "\n",
    "# M(theta0) = grad(Phi o g)(theta0).T * grad(Phi o g)(theta0)\n",
    "# This return M = f(theta0)\n",
    "\n",
    "def M_from_G(G):\n",
    "    return torch.matmul(torch.transpose(G,0,1),G)\n",
    "\n",
    "def M_from_theta(theta, G):\n",
    "    return M_from_G(G(inputs=theta))\n",
    "\n",
    "def M_factory(logscale,Phi):\n",
    "    S_from_theta = pknn_forward_factory(logscale,Phi)\n",
    "    #G = torch.func.jacfwd(S_from_theta)\n",
    "    G = functools.partial(torch.autograd.functional.jacobian, func=S_from_theta, create_graph=False,strategy=\"forward-mode\",vectorize=True)\n",
    "    M = functools.partial(M_from_theta,G=G)\n",
    "    return M\n",
    "\n",
    "def dist_from_M_and_theta0(t_candidat, t_ref, M):\n",
    "    return np.matmul(np.matmul(np.transpose(t_ref-t_candidat),M.cpu().detach().numpy()),t_ref-t_candidat)\n",
    "\n",
    "def dist_approximated_factory(M, t_ref):\n",
    "    return functools.partial(dist_from_M_and_theta0, M=M, t_ref=t_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4499768",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf4aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(2.400247964468862),\n",
       " np.float64(0.0700188044714488),\n",
       " np.float64(-4.999978530884291),\n",
       " np.float64(-4.99983759075039),\n",
       " np.float64(1.2362882382361523e-05)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetPath = \"default_parameters.csv\"\n",
    "parameters_name = [\"omega\",\"tau\",\"p\",\"d\",\"alpha\"]\n",
    "logscale = True\n",
    "Phi = FIRFilter()\n",
    "\n",
    "#Get the reference Theta\n",
    "\n",
    "theta_ref_index = 0\n",
    "DS = pd.read_csv(DatasetPath, index_col=0)\n",
    "theta_ref_line = DS.iloc[[theta_ref_index]]\n",
    "theta_ref = [ theta_ref_line[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ]\n",
    "\n",
    "#Find the knn (Naive and Approx)\n",
    "\n",
    "k = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3981bde-ab86-4082-902c-b8be46289610",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1eccf8-d015-451e-b9a6-ce543a7dac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10057369531250018\n",
      "0.095978074\n"
     ]
    }
   ],
   "source": [
    "theta2 = np.array([2.4498039582702016,0.6461548540239277,-1.7064752202175573,-1.0410779935838828,0.0562217157838597])\n",
    "\n",
    "theta1 = np.array([2.490387548888748,0.5584495826467211,-4.862062785726994,-2.9690459969445326,0.965225942518418])\n",
    "theta1bis = theta1 + np.array([0.0,0.0,0.0,0.0,0.001])\n",
    "\n",
    "logscale = True\n",
    "\n",
    "\n",
    "#############################\n",
    "M = M_factory(logscale,Phi)\n",
    "t = torch.tensor(theta1, requires_grad=True).to(device)\n",
    "M = M(t)\n",
    "dTheta = (theta1-theta1bis)\n",
    "distance_opti = np.matmul(np.matmul(np.transpose(dTheta),M.cpu().detach().numpy()),dTheta)\n",
    "\n",
    "print(distance_opti)\n",
    "\n",
    "#############################\n",
    "S_from_theta = pknn_forward_factory(logscale,Phi)\n",
    "distance_naive = np.linalg.norm(S_from_theta(theta1).cpu().detach().numpy() - S_from_theta(theta1bis).cpu().detach().numpy())**2\n",
    "\n",
    "print(distance_naive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
