{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a08083",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c2eeb-840a-4946-9432-26cc1ca6a76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06127a8c-52fc-456b-9503-eca3270ade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from src.forward import *\n",
    "from src.knn import *\n",
    "from src.ftm import constants as FTM_constants\n",
    "import IPython.display as ipd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44998c3d-8efb-4f7d-aaff-f4004bcab699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Phi definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd00b1d3-0b58-4480-ad83-2ad9da31f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIRFilter(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_type=\"hp\", coef=0.85, fs=44100, ntaps=101, plot=False):\n",
    "\n",
    "        \"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\n",
    "        super(FIRFilter, self).__init__()\n",
    "        self.filter_type = filter_type\n",
    "        self.coef = coef\n",
    "        self.fs = fs\n",
    "        self.ntaps = ntaps\n",
    "        self.plot = plot\n",
    "\n",
    "        import scipy.signal\n",
    "\n",
    "        if ntaps % 2 == 0:\n",
    "            raise ValueError(f\"ntaps must be odd (ntaps={ntaps}).\")\n",
    "\n",
    "        if filter_type == \"hp\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, -coef, 0]).view(1, 1, -1)\n",
    "        elif filter_type == \"fd\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, 0, -coef]).view(1, 1, -1)\n",
    "        elif filter_type == \"aw\":\n",
    "            # Definition of analog A-weighting filter according to IEC/CD 1672.\n",
    "            f1 = 20.598997\n",
    "            f2 = 107.65265\n",
    "            f3 = 737.86223\n",
    "            f4 = 12194.217\n",
    "            A1000 = 1.9997\n",
    "\n",
    "            NUMs = [(2 * np.pi * f4) ** 2 * (10 ** (A1000 / 20)), 0, 0, 0, 0]\n",
    "            DENs = np.polymul(\n",
    "                [1, 4 * np.pi * f4, (2 * np.pi * f4) ** 2],\n",
    "                [1, 4 * np.pi * f1, (2 * np.pi * f1) ** 2],\n",
    "            )\n",
    "            DENs = np.polymul(\n",
    "                np.polymul(DENs, [1, 2 * np.pi * f3]), [1, 2 * np.pi * f2]\n",
    "            )\n",
    "\n",
    "            # convert analog filter to digital filter\n",
    "            b, a = scipy.signal.bilinear(NUMs, DENs, fs=fs)\n",
    "\n",
    "            # compute the digital filter frequency response\n",
    "            w_iir, h_iir = scipy.signal.freqz(b, a, worN=512, fs=fs)\n",
    "\n",
    "            # then we fit to 101 tap FIR filter with least squares\n",
    "            taps = scipy.signal.firls(ntaps, w_iir, abs(h_iir), fs=fs)\n",
    "\n",
    "            # now implement this digital FIR filter as a Conv1d layer\n",
    "            self.fir = torch.nn.Conv1d(\n",
    "                1, 1, kernel_size=ntaps, bias=False, padding=ntaps // 2\n",
    "            )\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor(taps.astype(\"float32\")).view(1, 1, -1)\n",
    "\n",
    "        self.fir.weight.data = self.fir.weight.data.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            input (Tensor): Predicted signal (B, #channels, #samples).\n",
    "            target (Tensor): Groundtruth signal (B, #channels, #samples).\n",
    "        Returns:\n",
    "            Tensor: Filtered signal.\n",
    "        \"\"\"\n",
    "        input = torch.nn.functional.conv1d(\n",
    "            input.unsqueeze(0).to(torch.float), self.fir.weight.data, padding=self.ntaps // 2\n",
    "        )\n",
    "        return input.squeeze(0).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ae66-407e-4d72-b5d3-ba10952adeef",
   "metadata": {},
   "source": [
    "### Naive k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10daf5a-e2ef-423f-8bdc-2ab55e51920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_naive_factory(theta_ref,phi,logscale):\n",
    "    #calculation of the audio for the reference node\n",
    "    audio_ref = rectangular_drum(theta_ref, logscale=logscale,**FTM_constants)\n",
    "    phi_ref = phi(audio_ref)\n",
    "    def naiveDistFunction(theta):\n",
    "        audio_node = rectangular_drum(theta, logscale=logscale,**FTM_constants)\n",
    "        phi_node = phi(audio_node)\n",
    "        return (torch.sum(torch.pow(torch.subtract(phi_ref, phi_node), 2), dim=0)).cpu().detach().numpy()\n",
    "    return naiveDistFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3515fc4-0364-40c1-93e6-e420c076dd9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Approximated k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33743ea-c02a-4190-b362-9029c32f327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the M matrix\n",
    "\n",
    "# M(theta0) = grad(Phi o g)(theta0).T * grad(Phi o g)(theta0)\n",
    "# This return M = f(theta0)\n",
    "\n",
    "def M_from_G(G):\n",
    "    return torch.matmul(torch.transpose(G,0,1),G)\n",
    "\n",
    "def M_from_theta(theta, G):\n",
    "    return M_from_G(G(inputs=theta))\n",
    "\n",
    "def M_factory(logscale,Phi):\n",
    "    S_from_theta = pknn_forward_factory(logscale,Phi)\n",
    "    #G = torch.func.jacfwd(S_from_theta)\n",
    "    G = functools.partial(torch.autograd.functional.jacobian, func=S_from_theta, create_graph=False,strategy=\"forward-mode\",vectorize=True)\n",
    "    M = functools.partial(M_from_theta,G=G)\n",
    "    return M\n",
    "\n",
    "def dist_from_M_and_theta0(t_candidat, t_ref, M):\n",
    "    return np.matmul(np.matmul(np.transpose(t_ref-t_candidat),M.cpu().detach().numpy()),t_ref-t_candidat)\n",
    "\n",
    "def dist_approximated_factory(t_ref,Phi,logscale):\n",
    "    M = M_factory(logscale,Phi)\n",
    "    M = M(torch.tensor(t_ref, requires_grad=True).to(device))\n",
    "    return functools.partial(dist_from_M_and_theta0, M=M, t_ref=t_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1449854-d9e1-4f86-ba40-c69676fe25e5",
   "metadata": {},
   "source": [
    "### Create Parameters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67c2f51-28fe-4fad-a024-295d6041a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and write it to a CSV file for later use\n",
    "\n",
    "def create_DF(bounds, subdiv, path):\n",
    "    \n",
    "    #Linspace of every parameters of size k\n",
    "    Dbase = np.zeros((subdiv,5))\n",
    "    for i in range(5):\n",
    "        Dbase[:,i] = np.linspace(bounds[1][i][0],bounds[1][i][1],subdiv)\n",
    "    baseDF = pd.DataFrame(data=Dbase,columns=bounds[0])\n",
    "\n",
    "    #Product of the linspaces to get all the possible combinations (size subdiv**5, will take time)\n",
    "    D = list(product(baseDF['omega'],baseDF['tau'],baseDF['p'],baseDF['d'],baseDF['alpha']))\n",
    "    DF = pd.DataFrame(data=D,columns=bounds[0])\n",
    "\n",
    "    DF.to_csv(path)\n",
    "    \n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4499768",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288970fa-6ec7-43d5-9ca5-de42be0ebd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>omega</th>\n",
       "      <th>tau</th>\n",
       "      <th>p</th>\n",
       "      <th>d</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.400248</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>-4.999979</td>\n",
       "      <td>-4.999838</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.400248</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>-4.999979</td>\n",
       "      <td>-4.999838</td>\n",
       "      <td>0.052641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.400248</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>-4.999979</td>\n",
       "      <td>-4.999838</td>\n",
       "      <td>0.105271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.400248</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>-4.999979</td>\n",
       "      <td>-4.999838</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.400248</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>-4.999979</td>\n",
       "      <td>-4.999838</td>\n",
       "      <td>0.210529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199995</th>\n",
       "      <td>3.798137</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>-0.698980</td>\n",
       "      <td>-0.522998</td>\n",
       "      <td>0.789449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199996</th>\n",
       "      <td>3.798137</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>-0.698980</td>\n",
       "      <td>-0.522998</td>\n",
       "      <td>0.842078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199997</th>\n",
       "      <td>3.798137</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>-0.698980</td>\n",
       "      <td>-0.522998</td>\n",
       "      <td>0.894707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199998</th>\n",
       "      <td>3.798137</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>-0.698980</td>\n",
       "      <td>-0.522998</td>\n",
       "      <td>0.947336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199999</th>\n",
       "      <td>3.798137</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>-0.698980</td>\n",
       "      <td>-0.522998</td>\n",
       "      <td>0.999965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            omega       tau         p         d     alpha\n",
       "0        2.400248  0.070019 -4.999979 -4.999838  0.000012\n",
       "1        2.400248  0.070019 -4.999979 -4.999838  0.052641\n",
       "2        2.400248  0.070019 -4.999979 -4.999838  0.105271\n",
       "3        2.400248  0.070019 -4.999979 -4.999838  0.157900\n",
       "4        2.400248  0.070019 -4.999979 -4.999838  0.210529\n",
       "...           ...       ...       ...       ...       ...\n",
       "3199995  3.798137  0.799997 -0.698980 -0.522998  0.789449\n",
       "3199996  3.798137  0.799997 -0.698980 -0.522998  0.842078\n",
       "3199997  3.798137  0.799997 -0.698980 -0.522998  0.894707\n",
       "3199998  3.798137  0.799997 -0.698980 -0.522998  0.947336\n",
       "3199999  3.798137  0.799997 -0.698980 -0.522998  0.999965\n",
       "\n",
       "[3200000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boundaries\n",
    "\n",
    "bounds = [['omega', 'tau', 'p', 'd', 'alpha'],\n",
    " [(2.400247964468862, 3.798136579655672),\n",
    "  (0.0700188044714488, 0.7999966616122908),\n",
    "  (-4.999978530884291, -0.6989804486272966),\n",
    "  (-4.99983759075039, -0.5229983775344527),\n",
    "  (1.2362882382361523e-05, 0.9999649724709304)]]\n",
    "\n",
    "# Only run this to recreate the parameters CSV, this can take a long time to finish depending on the subdivision\n",
    "\n",
    "#create_DF(bounds=bounds, subdiv=20, path='data/default_parameters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eaf4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Dataset\n",
      "Naive knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200000/3200000 [7:21:26<00:00, 120.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3200000/3200000 [19:42<00:00, 2707.18it/s]\n"
     ]
    }
   ],
   "source": [
    "DatasetPath = \"data/default_parameters.csv\"\n",
    "parameters_name = [\"omega\",\"tau\",\"p\",\"d\",\"alpha\"]\n",
    "logscale = True\n",
    "Phi = FIRFilter()\n",
    "\n",
    "k = 100\n",
    "theta_ref_index = 0\n",
    "\n",
    "#Get the reference Theta\n",
    "print(\"Reading Dataset\")\n",
    "\n",
    "DS = pd.read_csv(DatasetPath, index_col=0)\n",
    "theta_ref_line = DS.iloc[[theta_ref_index]]\n",
    "theta_ref = [ theta_ref_line[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ]\n",
    "\n",
    "#Find the knn (Naive)\n",
    "print(\"Naive knn\")\n",
    "\n",
    "dist = dist_naive_factory(theta_ref, Phi, logscale)\n",
    "naive_neighbours,naive_time = find_neighbour(DatasetPath,k,dist,return_time=True,show_progress=True)\n",
    "\n",
    "#Find the knn (Approx)\n",
    "print(\"Approx knn\")\n",
    "\n",
    "dist = dist_approximated_factory(theta_ref, Phi, logscale)\n",
    "approx_neighbours,approx_time = find_neighbour(DatasetPath,k,dist,return_time=True,show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57ebcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive:\n",
      "        omega       tau         p         d     alpha\n",
      "0    2.400248  0.070019 -4.999979 -4.999838  0.000012\n",
      "1    2.400248  0.070019 -4.999979 -4.999838  0.052641\n",
      "2    2.400248  0.070019 -4.999979 -4.999838  0.000012\n",
      "3    2.400248  0.070019 -4.773610 -4.999838  0.000012\n",
      "4    2.400248  0.070019 -4.547242 -4.999838  0.000012\n",
      "..        ...       ...       ...       ...       ...\n",
      "96   2.400248  0.070019 -2.509927 -3.114853  0.000012\n",
      "97   2.400248  0.070019 -4.547242 -2.879230  0.000012\n",
      "98   2.400248  0.070019 -1.830822 -4.999838  0.000012\n",
      "99   2.400248  0.070019 -2.283559 -3.114853  0.000012\n",
      "100  2.400248  0.070019 -2.736295 -3.114853  0.000012\n",
      "\n",
      "[101 rows x 5 columns]\n",
      "\n",
      "approx:\n",
      "        omega       tau         p         d     alpha\n",
      "0    2.400248  0.070019 -4.999979 -4.999838  0.000012\n",
      "1    2.400248  0.070019 -4.999979 -4.999838  0.052641\n",
      "2    2.400248  0.070019 -4.999979 -4.999838  0.000012\n",
      "3    2.400248  0.070019 -4.773610 -4.999838  0.000012\n",
      "4    2.400248  0.070019 -4.547242 -4.999838  0.000012\n",
      "..        ...       ...       ...       ...       ...\n",
      "96   2.400248  0.146859 -2.736295 -4.764214  0.000012\n",
      "97   2.400248  0.146859 -3.868137 -4.999838  0.000012\n",
      "98   2.400248  0.146859 -2.509927 -4.764214  0.000012\n",
      "99   2.400248  0.146859 -3.641769 -4.999838  0.000012\n",
      "100  2.400248  0.108439 -0.698980 -4.999838  0.000012\n",
      "\n",
      "[101 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Write the neighbours to a CSV file \n",
    "\n",
    "print('naive:')\n",
    "naive_DL = np.transpose(np.column_stack((np.array(theta_ref),np.transpose(np.array(naive_neighbours)))))\n",
    "naive_DF = pd.DataFrame(naive_DL, columns=(parameters_name))\n",
    "print(naive_DF)\n",
    "naive_DF.to_csv(\"data/naive_knn.csv\")\n",
    "\n",
    "print('\\napprox:')\n",
    "approx_DL = np.transpose(np.column_stack((np.array(theta_ref),np.transpose(np.array(approx_neighbours)))))\n",
    "approx_DF = pd.DataFrame(approx_DL, columns=(parameters_name))\n",
    "print(approx_DF)\n",
    "approx_DF.to_csv(\"data/approx_knn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b3207-e43d-4d6c-a821-8a632052eaa1",
   "metadata": {},
   "source": [
    "# Method characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc00b36-707b-4264-8a79-e88f2b03b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined the list of parameters\n",
    "approx_neighbours = []\n",
    "naive_neighbours = []\n",
    "\n",
    "parameters_name = ['omega', 'tau', 'p', 'd', 'alpha']\n",
    "\n",
    "#Recover all parameters\n",
    "data = pd.read_csv(\"data/naive_knn.csv\", index_col=0)\n",
    "data_size = data.size\n",
    "for i in range(int(data_size/5)):\n",
    "    #Get phi of the neighbour\n",
    "    parameterLine = data.iloc[[i]]\n",
    "    theta = np.array([ parameterLine[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ])\n",
    "    approx_neighbours.append(theta)\n",
    "\n",
    "#Recover all parameters\n",
    "data1 = pd.read_csv(\"data/approx_knn.csv\", index_col=0)\n",
    "data_size = data.size\n",
    "for i in range(int(data_size/5)):\n",
    "    #Get phi of the neighbour\n",
    "    parameterLine = data1.iloc[[i]]\n",
    "    theta = np.array([ parameterLine[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ])\n",
    "    naive_neighbours.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa6d7f-bc85-4798-92c7-f093c33d1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours n° 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNeighbours n°\u001b[39m\u001b[33m\"\u001b[39m,i+\u001b[32m1\u001b[39m)\n\u001b[32m      6\u001b[39m audio = rectangular_drum(naive_neighbours[i],logscale=\u001b[38;5;28;01mTrue\u001b[39;00m,**FTM_constants)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ipd.display(\u001b[43mipd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m44100\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smale\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\lib\\display.py:130\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[43mAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smale\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\lib\\display.py:152\u001b[39m, in \u001b[36mAudio._make_wav\u001b[39m\u001b[34m(data, rate, normalize)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwave\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     scaled, nchan = \u001b[43mAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_normalize_with_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    154\u001b[39m     scaled, nchan = Audio._validate_and_normalize_without_numpy(data, normalize)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smale\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\lib\\display.py:172\u001b[39m, in \u001b[36mAudio._validate_and_normalize_with_numpy\u001b[39m\u001b[34m(data, normalize)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_normalize_with_numpy\u001b[39m(data, normalize) -> Tuple[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    174\u001b[39m         nchan = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smale\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:1213\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "#LISTEN HERE the truth\n",
    "\n",
    "#Calulate audios from the parameters\n",
    "for i in range(len(naive_neighbours)):\n",
    "    print(\"Neighbours n°\",i+1)\n",
    "    audio = rectangular_drum(naive_neighbours[i],logscale=True,**FTM_constants)\n",
    "    ipd.display(ipd.Audio(data=audio.cpu().detach(), rate=44100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2098b0b-2e61-402f-af36-ae4920ad46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTEN HERE the approximation\n",
    "\n",
    "#Calulate audios from the parameters\n",
    "approx_neighbours_audios = []\n",
    "for i in range(len(approx_neighbours)):\n",
    "    print(\"Neighbours n°\",i+1)\n",
    "    audio = rectangular_drum(naive_neighbours[i], True,**FTM_constants)\n",
    "    ipd.display(ipd.Audio(data=audio, rate=44100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4135ebf-d568-4767-89ff-728eef1aa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision and recall\n",
    "\n",
    "t_p = 0\n",
    "f_p = 0\n",
    "\n",
    "def inList(element,list_l):\n",
    "    for i in range(len(list_l)):\n",
    "        equal = True\n",
    "        for k in range(len(list_l[i])):\n",
    "            if(list_l[i][k]!= element[k]):\n",
    "                equal = False\n",
    "        if (equal):\n",
    "            return True\n",
    "\n",
    "for i in range(len(naive_neighbours)):\n",
    "    if (inList(approx_neighbours[i],naive_neighbours)):\n",
    "        t_p += 1\n",
    "    else:\n",
    "        f_p += 1\n",
    "print(\"Precision : \",t_p/len(naive_neighbours))\n",
    "print(\"Recall : \",f_p/len(naive_neighbours))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
