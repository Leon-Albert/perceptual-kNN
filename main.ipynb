{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a08083",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c2eeb-840a-4946-9432-26cc1ca6a76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06127a8c-52fc-456b-9503-eca3270ade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from src.forward import *\n",
    "from src.knn import *\n",
    "from src.ftm import constants as FTM_constants\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from rich.progress import track,Progress,BarColumn, TextColumn, SpinnerColumn, MofNCompleteColumn, TimeElapsedColumn, TimeRemainingColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44998c3d-8efb-4f7d-aaff-f4004bcab699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Phi definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00b1d3-0b58-4480-ad83-2ad9da31f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIRFilter(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_type=\"hp\", coef=0.85, fs=44100, ntaps=101, plot=False):\n",
    "\n",
    "        \"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\n",
    "        super(FIRFilter, self).__init__()\n",
    "        self.filter_type = filter_type\n",
    "        self.coef = coef\n",
    "        self.fs = fs\n",
    "        self.ntaps = ntaps\n",
    "        self.plot = plot\n",
    "\n",
    "        import scipy.signal\n",
    "\n",
    "        if ntaps % 2 == 0:\n",
    "            raise ValueError(f\"ntaps must be odd (ntaps={ntaps}).\")\n",
    "\n",
    "        if filter_type == \"hp\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, -coef, 0]).view(1, 1, -1)\n",
    "        elif filter_type == \"fd\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, 0, -coef]).view(1, 1, -1)\n",
    "        elif filter_type == \"aw\":\n",
    "            # Definition of analog A-weighting filter according to IEC/CD 1672.\n",
    "            f1 = 20.598997\n",
    "            f2 = 107.65265\n",
    "            f3 = 737.86223\n",
    "            f4 = 12194.217\n",
    "            A1000 = 1.9997\n",
    "\n",
    "            NUMs = [(2 * np.pi * f4) ** 2 * (10 ** (A1000 / 20)), 0, 0, 0, 0]\n",
    "            DENs = np.polymul(\n",
    "                [1, 4 * np.pi * f4, (2 * np.pi * f4) ** 2],\n",
    "                [1, 4 * np.pi * f1, (2 * np.pi * f1) ** 2],\n",
    "            )\n",
    "            DENs = np.polymul(\n",
    "                np.polymul(DENs, [1, 2 * np.pi * f3]), [1, 2 * np.pi * f2]\n",
    "            )\n",
    "\n",
    "            # convert analog filter to digital filter\n",
    "            b, a = scipy.signal.bilinear(NUMs, DENs, fs=fs)\n",
    "\n",
    "            # compute the digital filter frequency response\n",
    "            w_iir, h_iir = scipy.signal.freqz(b, a, worN=512, fs=fs)\n",
    "\n",
    "            # then we fit to 101 tap FIR filter with least squares\n",
    "            taps = scipy.signal.firls(ntaps, w_iir, abs(h_iir), fs=fs)\n",
    "\n",
    "            # now implement this digital FIR filter as a Conv1d layer\n",
    "            self.fir = torch.nn.Conv1d(\n",
    "                1, 1, kernel_size=ntaps, bias=False, padding=ntaps // 2\n",
    "            )\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor(taps.astype(\"float32\")).view(1, 1, -1)\n",
    "\n",
    "        self.fir.weight.data = self.fir.weight.data.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            input (Tensor): Predicted signal (B, #channels, #samples).\n",
    "            target (Tensor): Groundtruth signal (B, #channels, #samples).\n",
    "        Returns:\n",
    "            Tensor: Filtered signal.\n",
    "        \"\"\"\n",
    "        input = torch.nn.functional.conv1d(\n",
    "            input.unsqueeze(0).to(torch.float), self.fir.weight.data, padding=self.ntaps // 2\n",
    "        )\n",
    "        return input.squeeze(0).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ae66-407e-4d72-b5d3-ba10952adeef",
   "metadata": {},
   "source": [
    "### Naive k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10daf5a-e2ef-423f-8bdc-2ab55e51920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_naive_tensor_wise_factory(Phi,logscale):\n",
    "    return functools.partial(dist_naive_tensor_wise,Phi=Phi,logscale=logscale)\n",
    "\n",
    "def dist_naive_tensor_wise(tensor_candidates,t_ref,Phi,logscale,show_progress=False):\n",
    "    dist_tensor = torch.zeros(tensor_candidates.size(dim=0)).to(device)\n",
    "    \n",
    "    #calculation of the audio for the reference node\n",
    "    phi_ref = Phi(rectangular_drum(t_ref, logscale=logscale,**FTM_constants))\n",
    "\n",
    "    progress = Progress(\n",
    "            TextColumn(\"[DISTANCES] Naive Method   \"),\n",
    "            SpinnerColumn(),\n",
    "            BarColumn(),\n",
    "            MofNCompleteColumn(),\n",
    "            TimeElapsedColumn(),\n",
    "            TimeRemainingColumn(),\n",
    "            transient=True\n",
    "    )\n",
    "    if show_progress:\n",
    "        iterator = progress.track(range(tensor_candidates.size(dim=0)))\n",
    "    else:\n",
    "        iterator = range(tensor_candidates.size(dim=0))\n",
    "        \n",
    "    with progress:\n",
    "        for j in iterator:\n",
    "            phi_node = Phi(rectangular_drum(tensor_candidates[j,:], logscale=logscale,**FTM_constants))\n",
    "            dist_tensor[j] = torch.sum(torch.pow(torch.subtract(phi_ref, phi_node), 2), dim=0)\n",
    "   \n",
    "    return dist_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3515fc4-0364-40c1-93e6-e420c076dd9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Approximated k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33743ea-c02a-4190-b362-9029c32f327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the M matrix\n",
    "\n",
    "# M(theta0) = grad(Phi o g)(theta0).T * grad(Phi o g)(theta0)\n",
    "# This return M = f(theta0)\n",
    "\n",
    "def M_from_G(G):\n",
    "    return torch.matmul(torch.transpose(G,0,1),G)\n",
    "\n",
    "def M_from_theta(theta, G):\n",
    "    return M_from_G(G(inputs=theta))\n",
    "\n",
    "def M_factory(logscale,Phi):\n",
    "    S_from_theta = pknn_forward_factory(logscale,Phi)\n",
    "    #This one is the only autograd fct we can run on our computers\n",
    "    G = functools.partial(torch.autograd.functional.jacobian, func=S_from_theta, create_graph=False,strategy=\"forward-mode\",vectorize=True) \n",
    "    M = functools.partial(M_from_theta,G=G)\n",
    "    return M\n",
    "\n",
    "# Then we define the distance function\n",
    "\n",
    "def dist_approximated(t_candidate, t_ref, M_t_ref):\n",
    "    return torch.matmul(torch.matmul(torch.transpose(M_t_ref,0,1),torch.sub(t_ref,t_candidate)),torch.sub(t_ref,t_candidate))\n",
    "\n",
    "def dist_approximated_tensor_wise(tensor_candidates,t_ref,M,show_progress=False): \n",
    "    dist_tensor = torch.zeros(tensor_candidates.size(dim=0)).to(device)\n",
    "    M_ref = M(t_ref).to(float)\n",
    "\n",
    "    progress = Progress(\n",
    "        TextColumn(\"[DISTANCES] Approx Method  \"),\n",
    "        SpinnerColumn(),\n",
    "        BarColumn(),\n",
    "        MofNCompleteColumn(),\n",
    "        TimeElapsedColumn(),\n",
    "        TimeRemainingColumn(),\n",
    "        transient=True\n",
    "    )\n",
    "    if show_progress:\n",
    "        iterator = progress.track(range(tensor_candidates.size(dim=0)))\n",
    "    else:\n",
    "        iterator = range(tensor_candidates.size(dim=0))\n",
    "    \n",
    "    with progress:\n",
    "        for j in iterator:\n",
    "            dist_tensor[j] = dist_approximated(tensor_candidates[j,:],t_ref,M_ref)\n",
    "\n",
    "    return dist_tensor\n",
    "\n",
    "def dist_approximated_tensor_wise_factory(Phi,logscale):\n",
    "    M = M_factory(logscale,Phi)\n",
    "    return functools.partial(dist_approximated_tensor_wise,M=M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1449854-d9e1-4f86-ba40-c69676fe25e5",
   "metadata": {},
   "source": [
    "### Create Parameters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c2f51-28fe-4fad-a024-295d6041a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and write it to a CSV file for later use\n",
    "\n",
    "def create_DF(bounds, subdiv, path):\n",
    "    \n",
    "    #Linspace of every parameters of size k\n",
    "    Dbase = np.zeros((subdiv,5))\n",
    "    for i in range(5):\n",
    "        Dbase[:,i] = np.linspace(bounds[1][i][0],bounds[1][i][1],subdiv)\n",
    "    baseDF = pd.DataFrame(data=Dbase,columns=bounds[0])\n",
    "\n",
    "    #Product of the linspaces to get all the possible combinations (size subdiv**5, will take time)\n",
    "    D = list(product(baseDF['omega'],baseDF['tau'],baseDF['p'],baseDF['d'],baseDF['alpha']))\n",
    "    DF = pd.DataFrame(data=D,columns=bounds[0])\n",
    "\n",
    "    DF.to_csv(path)\n",
    "    \n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4499768",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288970fa-6ec7-43d5-9ca5-de42be0ebd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundaries\n",
    "\n",
    "bounds = [['omega', 'tau', 'p', 'd', 'alpha'],\n",
    " [(2.400247964468862, 3.798136579655672),\n",
    "  (0.0700188044714488, 0.7999966616122908),\n",
    "  (-4.999978530884291, -0.6989804486272966),\n",
    "  (-4.99983759075039, -0.5229983775344527),\n",
    "  (1.2362882382361523e-05, 0.9999649724709304)]]\n",
    "\n",
    "# Only run this to recreate the parameters CSV, this can take a long time to finish depending on the subdivision\n",
    "\n",
    "create_DF(bounds=bounds, subdiv=5, path='data/default_parameters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetPath = \"data/default_parameters.csv\"\n",
    "parameters_name = [\"omega\",\"tau\",\"p\",\"d\",\"alpha\"]\n",
    "logscale = True\n",
    "show_progress = True\n",
    "\n",
    "Phi = FIRFilter()\n",
    "k = 100\n",
    "nbr_ref = 3125\n",
    "\n",
    "id_refs = np.linspace(0,nbr_ref-1,nbr_ref).astype(int)\n",
    "\n",
    "#Find the knn (Approx)\n",
    "#dist = dist_naive_tensor_wise_factory(Phi, logscale)\n",
    "#naive_id,naive_dist = find_neighbour(DatasetPath,id_refs,k,dist,show_progress=show_progress)\n",
    "\n",
    "#Find the knn (Approx)\n",
    "dist = dist_approximated_tensor_wise_factory(Phi, logscale)\n",
    "approx_id,approx_dist = find_neighbour(DatasetPath,id_refs,k,dist,show_progress=show_progress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(approx_id)\n",
    "print(approx_dist)\n",
    "\n",
    "print(naive_id)\n",
    "print(naive_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ebcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the neighbours of the first ref point only to a CSV file \n",
    "\n",
    "naive_neighbours_id = naive_id[1,0:k]\n",
    "approx_neighbours_id = approx_id[1,0:k]\n",
    "\n",
    "data = torch.from_numpy(pd.read_csv(DatasetPath, index_col=0).to_numpy()).to(device).to(float)\n",
    "\n",
    "naive_neighbours = data[naive_neighbours_id,:].cpu()\n",
    "approx_neighbours = data[approx_neighbours_id,:].cpu()\n",
    "\n",
    "print('naive:')\n",
    "naive_DF = pd.DataFrame(naive_neighbours, columns=(parameters_name))\n",
    "print(naive_DF)\n",
    "naive_DF.to_csv(\"data/naive_knn.csv\")\n",
    "\n",
    "print('\\napprox:')\n",
    "approx_DF = pd.DataFrame(approx_neighbours, columns=(parameters_name))\n",
    "print(approx_DF)\n",
    "approx_DF.to_csv(\"data/approx_knn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b3207-e43d-4d6c-a821-8a632052eaa1",
   "metadata": {},
   "source": [
    "# Method characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc00b36-707b-4264-8a79-e88f2b03b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defined the list of parameters\n",
    "approx_neighbours = []\n",
    "naive_neighbours = []\n",
    "\n",
    "parameters_name = ['omega', 'tau', 'p', 'd', 'alpha']\n",
    "\n",
    "#Recover all parameters\n",
    "data = pd.read_csv(\"data/naive_knn.csv\", index_col=0)\n",
    "data_size = data.size\n",
    "for i in range(int(data_size/5)):\n",
    "    #Get phi of the neighbour\n",
    "    parameterLine = data.iloc[[i]]\n",
    "    theta = np.array([ parameterLine[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ])\n",
    "    naive_neighbours.append(theta)\n",
    "\n",
    "#Recover all parameters\n",
    "data1 = pd.read_csv(\"data/approx_knn.csv\", index_col=0)\n",
    "data_size = data.size\n",
    "for i in range(int(data_size/5)):\n",
    "    #Get phi of the neighbour\n",
    "    parameterLine = data1.iloc[[i]]\n",
    "    theta = np.array([ parameterLine[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ])\n",
    "    approx_neighbours.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91658f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = dist_naive_tensor_wise_factory(Phi, logscale)\n",
    "\n",
    "print(dist(torch.tensor(naive_neighbours),naive_neighbours[0]))\n",
    "print(\"aaaa\")\n",
    "print(dist(torch.tensor(approx_neighbours),approx_neighbours[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa6d7f-bc85-4798-92c7-f093c33d1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTEN HERE the truth\n",
    "\n",
    "#Calulate audios from the parameters\n",
    "for i in range(len(naive_neighbours)):\n",
    "    print(\"Neighbours n°\",i+1)\n",
    "    audio = rectangular_drum(naive_neighbours[i],logscale=True,**FTM_constants)\n",
    "    ipd.display(ipd.Audio(data=audio.cpu().detach(), rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2098b0b-2e61-402f-af36-ae4920ad46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTEN HERE the approximation\n",
    "\n",
    "#Calulate audios from the parameters\n",
    "for i in range(len(approx_neighbours)):\n",
    "    print(\"Neighbours n°\",i+1)\n",
    "    audio = rectangular_drum(approx_neighbours[i], True,**FTM_constants)\n",
    "    ipd.display(ipd.Audio(data=audio.cpu().detach(), rate=44100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4135ebf-d568-4767-89ff-728eef1aa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many neighbours to use \n",
    "\n",
    "precision = []\n",
    "\n",
    "for n in range(1,len(naive_neighbours)):\n",
    "\n",
    "    naive_neighbours_to_use = naive_neighbours[:n]\n",
    "    approx_neighbours_to_use = approx_neighbours[:n]\n",
    "\n",
    "    #Precision and recall\n",
    "\n",
    "    t_p = 0\n",
    "    f_p = 0\n",
    "\n",
    "    def inList(element,list_l):\n",
    "        for i in range(len(list_l)):\n",
    "            equal = True\n",
    "            for k in range(len(list_l[i])):\n",
    "                if(list_l[i][k]!= element[k]):\n",
    "                    equal = False\n",
    "            if (equal):\n",
    "                return True\n",
    "\n",
    "    for i in range(len(naive_neighbours_to_use)):\n",
    "        if (inList(approx_neighbours_to_use[i],naive_neighbours_to_use)):\n",
    "            t_p += 1\n",
    "        else:\n",
    "            f_p += 1\n",
    "\n",
    "    #print(\"Precision : \",t_p/len(naive_neighbours_to_use))\n",
    "    #print(\"Recall : \",f_p/len(naive_neighbours_to_use))\n",
    "\n",
    "    precision.append(t_p/len(naive_neighbours_to_use))\n",
    "\n",
    "x = np.linspace(1,len(naive_neighbours)-1,len(naive_neighbours)-1)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(x,precision)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
