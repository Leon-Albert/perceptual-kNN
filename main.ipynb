{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a08083",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c2eeb-840a-4946-9432-26cc1ca6a76f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06127a8c-52fc-456b-9503-eca3270ade1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from src.forward import *\n",
    "from src.knn import *\n",
    "from src.ftm import constants as FTM_constants\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44998c3d-8efb-4f7d-aaff-f4004bcab699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Phi definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd00b1d3-0b58-4480-ad83-2ad9da31f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIRFilter(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_type=\"hp\", coef=0.85, fs=44100, ntaps=101, plot=False):\n",
    "\n",
    "        \"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\n",
    "        super(FIRFilter, self).__init__()\n",
    "        self.filter_type = filter_type\n",
    "        self.coef = coef\n",
    "        self.fs = fs\n",
    "        self.ntaps = ntaps\n",
    "        self.plot = plot\n",
    "\n",
    "        import scipy.signal\n",
    "\n",
    "        if ntaps % 2 == 0:\n",
    "            raise ValueError(f\"ntaps must be odd (ntaps={ntaps}).\")\n",
    "\n",
    "        if filter_type == \"hp\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, -coef, 0]).view(1, 1, -1)\n",
    "        elif filter_type == \"fd\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, 0, -coef]).view(1, 1, -1)\n",
    "        elif filter_type == \"aw\":\n",
    "            # Definition of analog A-weighting filter according to IEC/CD 1672.\n",
    "            f1 = 20.598997\n",
    "            f2 = 107.65265\n",
    "            f3 = 737.86223\n",
    "            f4 = 12194.217\n",
    "            A1000 = 1.9997\n",
    "\n",
    "            NUMs = [(2 * np.pi * f4) ** 2 * (10 ** (A1000 / 20)), 0, 0, 0, 0]\n",
    "            DENs = np.polymul(\n",
    "                [1, 4 * np.pi * f4, (2 * np.pi * f4) ** 2],\n",
    "                [1, 4 * np.pi * f1, (2 * np.pi * f1) ** 2],\n",
    "            )\n",
    "            DENs = np.polymul(\n",
    "                np.polymul(DENs, [1, 2 * np.pi * f3]), [1, 2 * np.pi * f2]\n",
    "            )\n",
    "\n",
    "            # convert analog filter to digital filter\n",
    "            b, a = scipy.signal.bilinear(NUMs, DENs, fs=fs)\n",
    "\n",
    "            # compute the digital filter frequency response\n",
    "            w_iir, h_iir = scipy.signal.freqz(b, a, worN=512, fs=fs)\n",
    "\n",
    "            # then we fit to 101 tap FIR filter with least squares\n",
    "            taps = scipy.signal.firls(ntaps, w_iir, abs(h_iir), fs=fs)\n",
    "\n",
    "            # now implement this digital FIR filter as a Conv1d layer\n",
    "            self.fir = torch.nn.Conv1d(\n",
    "                1, 1, kernel_size=ntaps, bias=False, padding=ntaps // 2\n",
    "            )\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor(taps.astype(\"float32\")).view(1, 1, -1)\n",
    "\n",
    "        self.fir.weight.data = self.fir.weight.data.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            input (Tensor): Predicted signal (B, #channels, #samples).\n",
    "            target (Tensor): Groundtruth signal (B, #channels, #samples).\n",
    "        Returns:\n",
    "            Tensor: Filtered signal.\n",
    "        \"\"\"\n",
    "        input = torch.nn.functional.conv1d(\n",
    "            input.unsqueeze(0).to(torch.float), self.fir.weight.data, padding=self.ntaps // 2\n",
    "        )\n",
    "        return input.squeeze(0).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ae66-407e-4d72-b5d3-ba10952adeef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Naive k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10daf5a-e2ef-423f-8bdc-2ab55e51920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_naive_factory(theta_ref,phi,logscale):\n",
    "    #calculation of the audio for the reference node\n",
    "    audio_ref = rectangular_drum(theta_ref, logscale=logscale,**FTM_constants)\n",
    "    phi_ref = phi(audio_ref)\n",
    "    def naiveDistFunction(theta):\n",
    "        audio_node = rectangular_drum(theta, logscale=logscale,**FTM_constants)\n",
    "        phi_node = phi(audio_node)\n",
    "        return (torch.sum(torch.pow(torch.subtract(phi_ref, phi_node), 2), dim=0)).cpu().detach().numpy()\n",
    "    return naiveDistFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3515fc4-0364-40c1-93e6-e420c076dd9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Approximated k neighbours search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33743ea-c02a-4190-b362-9029c32f327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the M matrix\n",
    "\n",
    "# M(theta0) = grad(Phi o g)(theta0).T * grad(Phi o g)(theta0)\n",
    "# This return M = f(theta0)\n",
    "\n",
    "def M_from_G(G):\n",
    "    return torch.matmul(torch.transpose(G,0,1),G)\n",
    "\n",
    "def M_from_theta(theta, G):\n",
    "    return M_from_G(G(inputs=theta))\n",
    "\n",
    "def M_factory(logscale,Phi):\n",
    "    S_from_theta = pknn_forward_factory(logscale,Phi)\n",
    "    #G = torch.func.jacfwd(S_from_theta)\n",
    "    G = functools.partial(torch.autograd.functional.jacobian, func=S_from_theta, create_graph=False,strategy=\"forward-mode\",vectorize=True)\n",
    "    M = functools.partial(M_from_theta,G=G)\n",
    "    return M\n",
    "\n",
    "def dist_from_M_and_theta0(t_candidat, t_ref, M):\n",
    "    return np.matmul(np.matmul(np.transpose(t_ref-t_candidat),M.cpu().detach().numpy()),t_ref-t_candidat)\n",
    "\n",
    "def dist_approximated_factory(t_ref,Phi,logscale):\n",
    "    M = M_factory(logscale,Phi)\n",
    "    M = M(torch.tensor(t_ref, requires_grad=True).to(device))\n",
    "    return functools.partial(dist_from_M_and_theta0, M=M, t_ref=t_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1449854-d9e1-4f86-ba40-c69676fe25e5",
   "metadata": {},
   "source": [
    "### Create Parameters Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c2f51-28fe-4fad-a024-295d6041a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and write it to a CSV file for later use\n",
    "\n",
    "def create_DF(bounds, subdiv, path):\n",
    "    \n",
    "    #Linspace of every parameters of size k\n",
    "    Dbase = np.zeros((subdiv,5))\n",
    "    for i in range(5):\n",
    "        Dbase[:,i] = np.linspace(bounds[1][i][0],bounds[1][i][1],subdiv)\n",
    "    baseDF = pd.DataFrame(data=Dbase,columns=bounds[0])\n",
    "\n",
    "    #Product of the linspaces to get all the possible combinations (size subdiv**5, will take time)\n",
    "    D = list(product(baseDF['omega'],baseDF['tau'],baseDF['p'],baseDF['d'],baseDF['alpha']))\n",
    "    DF = pd.DataFrame(data=D,columns=bounds[0])\n",
    "\n",
    "    DF.to_csv(path)\n",
    "    \n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4499768",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288970fa-6ec7-43d5-9ca5-de42be0ebd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundaries\n",
    "\n",
    "bounds = [['omega', 'tau', 'p', 'd', 'alpha'],\n",
    " [(2.400247964468862, 3.798136579655672),\n",
    "  (0.0700188044714488, 0.7999966616122908),\n",
    "  (-4.999978530884291, -0.6989804486272966),\n",
    "  (-4.99983759075039, -0.5229983775344527),\n",
    "  (1.2362882382361523e-05, 0.9999649724709304)]]\n",
    "\n",
    "# Only run this to recreate the parameters CSV, this can take a long time to finish depending on the subdivision\n",
    "\n",
    "#create_DF(bounds=bounds, subdiv=5, path='default_parameters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Dataset\n",
      "Naive knn\n",
      "3125\n",
      "([array([ 2.40024796,  0.0700188 , -4.99997853, -4.99983759,  0.25000052]), array([ 2.40024796e+00,  7.00188045e-02, -4.99997853e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -3.92472901e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -2.84947949e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -2.84947949e+00, -3.88062779e+00,\n",
      "        1.23628824e-05])], [23.96194100379944, 0.03111433982849121])\n",
      "Approx knn\n",
      "3125\n",
      "([array([ 2.40024796,  0.0700188 , -4.99997853, -4.99983759,  0.25000052]), array([ 2.40024796e+00,  7.00188045e-02, -4.99997853e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -3.92472901e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -2.84947949e+00, -4.99983759e+00,\n",
      "        1.23628824e-05]), array([ 2.40024796e+00,  7.00188045e-02, -1.77422997e+00, -4.99983759e+00,\n",
      "        1.23628824e-05])], [0.23610377311706543, 0.0017962455749511719])\n"
     ]
    }
   ],
   "source": [
    "DatasetPath = \"default_parameters.csv\"\n",
    "parameters_name = [\"omega\",\"tau\",\"p\",\"d\",\"alpha\"]\n",
    "logscale = True\n",
    "Phi = FIRFilter()\n",
    "\n",
    "k = 5\n",
    "theta_ref_index = 0\n",
    "\n",
    "#Get the reference Theta\n",
    "print(\"Reading Dataset\")\n",
    "\n",
    "DS = pd.read_csv(DatasetPath, index_col=0)\n",
    "theta_ref_line = DS.iloc[[theta_ref_index]]\n",
    "theta_ref = [ theta_ref_line[parameters_name[k]].iloc[0] for k in range(len(parameters_name)) ]\n",
    "\n",
    "#Find the knn (Naive)\n",
    "print(\"Naive knn\")\n",
    "\n",
    "dist = dist_naive_factory(theta_ref, Phi, logscale)\n",
    "naive_neighbours = find_neighbour(DatasetPath,k,dist,return_time=True)\n",
    "\n",
    "#Find the knn (Approx)\n",
    "print(\"Approx knn\")\n",
    "\n",
    "dist = dist_approximated_factory(theta_ref, Phi, logscale)\n",
    "approx_neighbours = find_neighbour(DatasetPath,k,dist,return_time=True)\n",
    "\n",
    "#Qualify results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
