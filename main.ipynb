{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06127a8c-52fc-456b-9503-eca3270ade1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2944)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.forward import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd00b1d3-0b58-4480-ad83-2ad9da31f3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFIRFilter\u001b[39;00m(\u001b[43mtorch\u001b[49m.nn.Module):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_type=\u001b[33m\"\u001b[39m\u001b[33mhp\u001b[39m\u001b[33m\"\u001b[39m, coef=\u001b[32m0.85\u001b[39m, fs=\u001b[32m44100\u001b[39m, ntaps=\u001b[32m101\u001b[39m, plot=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      4\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class FIRFilter(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_type=\"hp\", coef=0.85, fs=44100, ntaps=101, plot=False):\n",
    "        \"\"\"Initilize FIR pre-emphasis filtering module.\"\"\"\n",
    "        super(FIRFilter, self).__init__()\n",
    "        self.filter_type = filter_type\n",
    "        self.coef = coef\n",
    "        self.fs = fs\n",
    "        self.ntaps = ntaps\n",
    "        self.plot = plot\n",
    "\n",
    "        import scipy.signal\n",
    "\n",
    "        if ntaps % 2 == 0:\n",
    "            raise ValueError(f\"ntaps must be odd (ntaps={ntaps}).\")\n",
    "\n",
    "        if filter_type == \"hp\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, -coef, 0]).view(1, 1, -1)\n",
    "        elif filter_type == \"fd\":\n",
    "            self.fir = torch.nn.Conv1d(1, 1, kernel_size=3, bias=False, padding=1)\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor([1, 0, -coef]).view(1, 1, -1)\n",
    "        elif filter_type == \"aw\":\n",
    "            # Definition of analog A-weighting filter according to IEC/CD 1672.\n",
    "            f1 = 20.598997\n",
    "            f2 = 107.65265\n",
    "            f3 = 737.86223\n",
    "            f4 = 12194.217\n",
    "            A1000 = 1.9997\n",
    "\n",
    "            NUMs = [(2 * np.pi * f4) ** 2 * (10 ** (A1000 / 20)), 0, 0, 0, 0]\n",
    "            DENs = np.polymul(\n",
    "                [1, 4 * np.pi * f4, (2 * np.pi * f4) ** 2],\n",
    "                [1, 4 * np.pi * f1, (2 * np.pi * f1) ** 2],\n",
    "            )\n",
    "            DENs = np.polymul(\n",
    "                np.polymul(DENs, [1, 2 * np.pi * f3]), [1, 2 * np.pi * f2]\n",
    "            )\n",
    "\n",
    "            # convert analog filter to digital filter\n",
    "            b, a = scipy.signal.bilinear(NUMs, DENs, fs=fs)\n",
    "\n",
    "            # compute the digital filter frequency response\n",
    "            w_iir, h_iir = scipy.signal.freqz(b, a, worN=512, fs=fs)\n",
    "\n",
    "            # then we fit to 101 tap FIR filter with least squares\n",
    "            taps = scipy.signal.firls(ntaps, w_iir, abs(h_iir), fs=fs)\n",
    "\n",
    "            # now implement this digital FIR filter as a Conv1d layer\n",
    "            self.fir = torch.nn.Conv1d(\n",
    "                1, 1, kernel_size=ntaps, bias=False, padding=ntaps // 2\n",
    "            )\n",
    "            self.fir.weight.requires_grad = False\n",
    "            self.fir.weight.data = torch.tensor(taps.astype(\"float32\")).view(1, 1, -1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            input (Tensor): Predicted signal (B, #channels, #samples).\n",
    "            target (Tensor): Groundtruth signal (B, #channels, #samples).\n",
    "        Returns:\n",
    "            Tensor: Filtered signal.\n",
    "        \"\"\"\n",
    "        input = torch.nn.functional.conv1d(\n",
    "            input, self.fir.weight.data, padding=self.ntaps // 2\n",
    "        )\n",
    "        return input\n",
    "\n",
    "F = FIRFilter()\n",
    "\n",
    "def Phi(x):\n",
    "    x.unsqueeze_(0)\n",
    "    x = x.to(torch.float)\n",
    "    x = x.to(\"cpu\") #TODO check for CUDA\n",
    "    return F.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1eccf8-d015-451e-b9a6-ce543a7dac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2 = [2.4498039582702016,0.6461548540239277,-1.7064752202175573,-1.0410779935838828,0.0562217157838597]\n",
    "theta1 = [2.490387548888748,0.5584495826467211,-4.862062785726994,-2.9690459969445326,0.965225942518418]\n",
    "logscale = True\n",
    "\n",
    "S = pnp_forward_factory(logscale,Phi)\n",
    "\n",
    "loss = S(theta1)\n",
    "\n",
    "print(torch.linalg.vector_norm(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
